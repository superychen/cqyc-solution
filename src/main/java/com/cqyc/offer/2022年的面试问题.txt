

你好，面试官，我是20年毕业的，19年在重庆有过半年的一个实习经历，
主要做的一个企业与企业，企业与个人之间能够实现互相签订电子合同的一个签章系统，在实习过程中对一些开发规范、java框架有了大致的了解。
在20年3月份加入永辉，任职到现在，在永辉主要是负责B端供应链这一块，其中主要参与的项目有采购中台，开放平台，供零在线这三个项目。
其中采购中台是一个面向集团以及旗下子公司商行、品类、财务等用户搭建的数字化平台。我主要负责的采购中台寻源管理，也就是供应商中心。
再加入永辉期间，主要参与的有供应链数字化改造，协同平台功能建设，以及sass化改造等。目前对永辉供应链相关的一些业务，然后对java常用的一些api、框架等有一定的了解
在闲暇之余也会对java目前一些流行的技术或者知识进行一个了解。



项目简介：
其中在采购中台中负责的是供应商中心，它主要的是一个面向集团或子公司商行、品类、财务等用户搭建的数字化平台。集成了供应商管理，供应商生命周期，证件管理，
并且向各个业务系统提供稳定的、较为实时的数据服务。供应商的基础数据，采购视图，公司视图，以及供应商的采购信息数据。

供零在线平台聚焦于供应商用户管理、寻源管理、采购合同、证件合规、对账结算、数据报表协同等核心业务，利用移动端的便利性，将零售商和供应商紧密联系起来。形成一个零供协同的目的。
简单的理解就是供零在线是对供应商提供的一个客户端，就是供应链中的C端，采购中台就是一个服务端，主要服务用户是集团内部人员，包括采购、财务等人员。供应商在供零在线提交合作意向单之后
会进入到一个审核阶段，此时采购中台对接到蓝零的流程引擎，在由商品行政岗人员审核，通过之后会进行转办到采购高经，审核通过之后，进行线上或者线下的一个洽购洽谈，进入到供应商引入流程。
供应商引入主要由供应商、采购中台、外部平台比如1233、彩食鲜等来源进行一个引入，会根据提交数据，走到对应流程节点进行流程扭转，在流程结束后会将数据上传至sap中，sap生成最终的供应商编码，
生成后下发至中间表中，由定时任务处理落入供应商主数据中。至此供应商彻底入驻永辉。入驻后在由合同专员通过线下谈判，约定相关合同条款后。
在采购中台合同中心录入对应合同模版，然后在发起工作流审核，再经过相关处理人审批后，会将数据下发至我们的中间表中，
然后在我们这边初始化合同模版数据，此时状态修改后，由定时任务推送相关短信到供应商。供应商在进行线上盖章，签署完成之后回调中台端进行商行签署的流程。
最后双方签署已完成之后有合同专员拉取合同信息。最终会到对账结算模块中生成相关的费用单。据此合同流程结束。

    供应商后续进行新品引入相关流程。
引入流程也是数据生成审批流之后，对接到流程引擎进行流程处理，流程结束后数据上传至sap生成正式商品编码，最后下发至商品中间表，最后落地商品主数据中，
包括商品基础信息，大区商品，货源信息，最终由canal读取mysql binlog中的数据，读取之后会同步到es中，这里es其实是做了一个宽表处理的，
其实就是当成一个重点做数据搜索的数据库，然后再把一些热点供应商的商品key存储在redis中，至此一个商品信息就正式录入到永辉。
在后续的订单操作中，我以一条黄瓜鱼为例，它在我们门店中销售给对应的消费者，当门店卖完了之后，需要补充对应货物的时候，这时门店的采购经理会进行采购订单的需求，
其中就包括供应商直送，或者永辉物流直送，以及门店调拨等方式进行。此时就会在采购中台生成一个采购单，一系列处理之后，
会通知到供应商进行订单发送，或者仓储中心进行补货，此时如果不是供应商直送，供应商会发货到wms，就是永辉的物流中心，此时wms进行验货入库，
此时会调用到库存中心，进入库存更新，最后生成商品凭证，这个商品凭证回传到采购中台，此时一个订单正式生成完成，
这个时候就会到供零在线在发一个订货通知单，供应商可以在供零在线查询对应的订货通知单。商品最后到门店后，进行关单处理
。此时商品正式在门店进行销售。每年的永辉的采购订单营业额大约是在3个亿左右。


在去年从0-1构建的一个开放平台的项目，主要是做的一个将供应中台具备共享能力以及一些有价值的服务进行互联网方式的开放，供第三方调用，
并提供第三方商户可快速的进行访问的开放平台门户，帮助供应商、零售快速商实现生意的闭环。目前能力使用方有：外部供应商，各个战区的烟草公司，以及发改委政府机构等。其中对外提供的能力包括统一租户平台（账号管理，租户创建，权限管理），统一开放平台（统一的请求入口，鉴权方式，服务报文的加解密，异常告警，限流管理，请求统计），后台（管理包括API 管理，用户入驻，计费，sdk文档，应用管理, 黑白名单），统一数据推送平台（推送任务管理，任务自动重试，外部文件上传），海星统一监控（请求监控，资源监控，业务告警，异常统计，日志管理）





笔试：
1、前中后序遍历
2、jvm堆区域划分


第一次外包：（其实就是java基础）
1、list循环做操作，会出问题嘛
2、关闭流显示去关闭，finnaly
3、java7、java8的新特性
	java8的新特性：01: lambad表达式，允许把函数作为一个方法的参数。 02: 函数式接口，一个有且仅有一个抽象方法，但是可以有很多非抽象方法的接口，可以隐式转换为lambad表达式。 03:方 法引用：直接引用对象方法或构造器，与lambada联合使用，可以使语言构造紧筹简洁，减少冗余代码。 04:默认方法：接口中的default. 05: stream api：把真正的函数式编程引入到java中。   06:option类：用来解决空指针异常  07: date time api: 加强时间处理

4、List(对付顺序的好帮手)：存储的元素是有序的、可重复的。  set: 存储的元素是无序的，不可重复。 Map：使用键值对（key-value）存储，类似于数学上的函数y=f(x), key无序、不可重复的，value是无序的、可重复的。
	list: 
		arrayList: 底层基于数组，适用于随机访问查询,并且它实现了RandomAccess， 标识为快速随机访问功能。 线程不安全，如果想安全，使用CopyOnWriteArrayList
		Vector: 线程安全，性能不好
		LinkedList: 底层使用双向链表,节点插入、删除高效，随机访问性能比动态数组慢， 不安全，想安全使用ConcurrentLinkedQueue
	set: 
		HashSet: 基于hashMap实现的，底层采用hashMap保存元素，线程不安全，能存null
		LinkedHashSet: linkedHashSet是HashSet的子类，并且内部通过linkedHashMap实现。
		treeSet: 有序、唯一，红黑树
	map:
		HashMap: 1.7数组+链表， 1.8又了一个变化，链表长度当大于64的时候，先判断是否先进行数组扩容，数组长度小于64先扩容数组，如果大于，转换成红黑树。线程不安全，如果想安全，使用ConcurrentHashMap,初始值默认16, 扩充时为2的幂次方
		LinkedHashMap: 继承于hashMap, 底层还是由数据+链表， 再此基础上增加了一条双向链表，使得键值对插入时候的顺序行。
		HashTable: 数组 + 链表，线程安全的，性能懂得都懂，不能存储null的键
		TreeMap: 红黑树（自平衡的排序二叉树）

5、java中的队列有哪些？
	queue继承于collection接口。其中linklist实现dequeue
	未实现阻塞接口的：01: linkedList实现了deque接口，受限的队列。 02: priorityQueue: 优先队列，本质维护了一个有序列表，自然排序，也可传递comparator构造函数实现自定义排序。
	     03: concurrentLinkedQueue: 基于链表，线程安全的队列，增加删除O(1) 查找O(n)
	实现阻塞接口的： 实现blockqueue五个阻塞队列，线程阻塞时，不能直接添加和删除元素，等到有空间或者元素时，才进行操作。
		01: ArrayBlockingQueue: 基于数组的有界队列。02: linkedBlockingQueue: 基于链表的有界队列。 03: ProiporityBlcokingQueue: 基于优先次序的无界队列。 04: delayQueue: 基于时间的优先队列。05: synchronousQueue: 内部没有容器的队列，特别，面试的时候不说。

6、java数组和链表两种结构的操作效率		     
	01: 数组静态分配内存，链表动态分配内存 02: 数组在内存中连续，链表不连续。03: 数组元素在栈区，链表元素在堆区。04:数组下标定位，时间复杂度O(1),链表循环O(N)。 05:插入链表O(1)

7、迭代器：提供一种方法访问一个容器对象中的各个元素，而又不需要暴露该对象的内部细节。如果在迭代器里面进行容器的修改、删除，则会跑出对应异常

5、hashmap底层处理实现
	01、1.8之前底层是基于数组加链表的方式，在经过计算的hashcode之后，继续会有一个扰乱函数，其目的是为了减少hash碰撞，主要实现就是高16位和低16位进行一个异或处理，然后得到一个hash值，然后进行对应的一个寻址优化，也就是对数组进行取模运算，（n-1）& hash来判断这个元素放在当前的那个数组下标中，如果遇到hash冲突，就将其形成一个链表放在链表后，然后如果hash冲突超过64位之后，先去判断一手这个数组长度有没有大于64，没有先进行数组的扩容，反之转换为红黑树进行处理。

	02、hashmap中的死循环问题：其实就是在并发下rehash导致的链表的值出现循环的情况，1.8之后已经修复，不过本身在并发情况下hashmap也会存在其他问题，所以并发情况还是使用concurrentHashMap

	03、hashmap put方法：01：对key的hashcode()做hash计算，计算下标 02: 没碰撞直接放在bucket 03: 如果碰撞了，以链表的形式存在数组中          									04:如果碰撞导致链表过长，就把链表转成红黑树，05: 如果节点存在就替换old value 06: 如果慢了，负载因子 * 当前容量，进行resize 								07:此时得到下标值，开始put数据进入数组

	04、 hashmap get方法： 01: 对key进行hashcode做hash计算，计算index. 02: 如果bucket里的第一个节点里直接命中，则直接返回  03: 如果有冲突，则通过key.equals(k)去查找对应的entry, 04:若为树，则在树中通过key.equals(k)查找，O(logn) 05: 若为链表，则在链表中通过key.equals(k)查找，O(n)

	05、hashmap 1.8改动了什么：01:数据 + 链表的结构改为了数组+链表+红黑树 02:优化了高位运算的hash算法。 03:扩容后，元素要么在原位置，要么在原位置移动了2次幂的位置，链表顺序不变。
	不会在出现死循环的问题。

	06、hash冲突的解决方案：1、开放定址法，发现冲突了，用这个某种探测算法虚招下一个空的散列地址，只要足够大，总能找到一个空的地址。比如线性探测，冲突就顺序找下一个位置，直到找到空位置
		2、在hash，冲突时计算另一种hash算法，这样就不用产生聚集，会增加计算时间。  3、链地址法：hashmap里面的使用，上面有。

	07、hashmap高16和低16位做处理，主要是扰乱函数，解决hash碰撞的问题，让高位也参与运算，比如后四位一样，高位不一样，进行后续 hash & (n-1)的时候，得到的索引是一样的，就会有冲突问题嘛，为了避免这种问题，就有高16位和低16位异或处理	


6、String类为什么是final
	主要是为了安全性和效率的缘故
	01: 为了实现字符串池（final修饰的代表存储数据的不可变更性，仅仅是引用地址不变，本身值会变，所以加上private,两者保证了不可变性，这样才能实现字符串池，可以节约很多heap空间，因为不同的字符串变量可能都指向池中的同一个字符串，如果是可变的话，改了值，等于其余变量指向它的都会跟着改变） 
	02: 为了线程安全 （如果是可变的，如果数据库用户名密码这些，如果有人钻空子，改变字符串指向对象的值，就会造成安全漏洞）
	03: 为了实现string可以创建HashCode不可变性 （不可变，它的hashcode被缓存，非常适合map中的键，处理速度就快过其他键的值）

7、如何自己手写一个hashmap?
	1、这个参考hashmap里面的实现原理。后面要自己去手撸一个再去说。先定义其中的方法，和存放数据的entry,然后再去说entry里面定义和实现，再说应该定义的成员变量。然后构造方法，进行初始化长度或者说entry的长度。定义我们自己的hash函数，取模运算。再去说实现put方法，先算出下表，然后判断entry是不是为空，为空就直接放入，冲突的话，将老数据往后移，新数据放在链表头，再说说在put时考虑的一些扩容啊，扩容时打乱重新hash的过程，用list元素去装，然后进行扩容这些的。然后再说说get方法的实现，这就比较简单了，根据khash找到下表，然后递归去找到对应的value值就好了。

8、深拷贝和浅拷贝
	拷贝对象时，只对基本数据类型进行拷贝，对引用数据类型进行引用传递，没有真实创建新对象。反之，对引用数据类型进行拷贝时，创建了一个新对象，并复制其成员变量，则认为深拷贝。
	实现cloneable接口，继承clone方法，如果一个对象只有基本数据类型，用clone方法获取就是这个对象的深拷贝，如果内部还有引用数据类型，那就是浅拷贝的操作。
	深拷贝还有一种方式，序列化，序列化一个对象后，在反序列化回来，就可以得到一个新的对象。




第二次外包(javaweb面试题)
1、session 和cookie区别与联系
	01:作用范围不同：cookie保存在客户端，session保存在服务端。
	02:存取方式和大小不同：cookie只能保存ASCII，session可以存任意数据。 cookie单个不超过4K,session可存储数据远高于cookie   03：有效期不同，cookie可设置长时间保持，比如默认登陆信息, session一般失效时间较短，客户端关闭或session超时都会失效。 04:隐私设置不同，cookie存在客户端，数据容易获取，不安全，session存在服务端，安全性好一点。 

2、转发和重定向
	01：发生位置不同：转发是在服务器上的，重定向是发生在浏览器上的  02: 用法不同：就是代码实现不一样，一个是request.getRequestDispatcher(), 一个是response.send()。 03: 去往url范围不同：转发只能去往当前web应用的资源。重定向可以去往任一资源 04: 传递数据类型不同，转发的request对象可以传递各种类型的数据，包括对象，重定向传递字符串。         05: 跳转时间不同：转发立即跳转，重定向等整个页面执行完成跳转。

3、什么是servlet?
	servlet是运行在web服务器的小型java程序，通常通过http协议接受和相应来自web客户端的请求。

4、	servlet的生命周期
  	01: init(第一次请求资源时，进行初始化)。02: service(第二次执行service,方法内部根据请求方式不同，调用不同的doget和dopost) 03: destory(servlet关闭时，执行销毁)

 5、会话作用域：01: page域(数据在一个页面范围内有效，通过pageContext访问)。02:request域：(数据在一个服务器范围内有效，通过request对象访问). 03: session域(数据在范围内有效)
 	04:applicaiton域(数据在一个应用服务器范围有效)

 6、http响应的结构：
 	01:状态码。  02: HTTP头部，包含更多的响应信息。03: 主体（html，图片。）	

 7、jsp和servlet的区别：
 	jsp是servelt的扩展，本质上是servlet的简易版本。不同点是：servelet引用逻辑在java文件汇总，并且完全从表示层脱离出来。jsp是java和html的结合，生产jsp文件，侧重于视图，servlet侧重于逻辑	

 8、session的生命周期： 
   	01: 何时生效（在用户第一次访问服务器的时创建） 02: 何时失效（长时间未活动从内存清除，session失效，默认20分钟。调用session invalidate方法）	

第三次外包：
白嫖我知识
fiegn和dubbo区别
业务问题居多，开放平台数据传输方式
对接外部系统时一对多的情况，怎么保证接口加密性
没啥技术意义
skywalking告警如何实现



电话面试：
1、redis相关面试题，如何保证热点数据，过期时间策略配置，缓存雪崩三件套操作
2、mysql分区表，sharding如何落表的，mysql做过哪些优化
3、静态绑定和动态绑定
	当编译时确定对象的类型时，被称为静态绑定。如果类有private, final或static方法，则有静态绑定。
	当在运行时确定对象的类型时，被称为动态绑定。

4、aop几个通知，然后aop的应用场景
5、业务介绍要显得牛皮一点

6、JMM内存管理
	java内存模型，它本身是一种抽象出来的概念，并不真实存在，它其实就是描述一种规则或着规范。
	它有三大特性嘛、原子性（要么全部执行，要么全部不执行），可见性（只要有一个线程对一个共享变量进行修改，其他线程都能马上收到通知，立刻获取最新值），
	  有序性（总结一句话就是在本线程观察，所有操作都是有序的，在其他线程观察另外的线程的时候，它是无序的。其实指的就是单线程内执行串行代码，能够保证执行的一个有序性，在多线程中，由于操作系统的指令重排，或者说主内存与本地内存同步数据的延迟性，导致有序性的一个问题，在Java中，提供了volatile和synchronized来保证操作的一个有序性）
		还有一个指令重排后，java引入happens-before原则，比如什么加锁必须要在解锁前面完成，volatile必须是先读后写，线程中断必须要发生在检测中断代码之前这些的，总共8条。
		volatile底层用所谓的内存屏障去禁止指令重排，以此来保证有序性，也通过那个加lock锁的操作，通过系统的嗅探去将其他线程内存值失效，保证可见性。

7、定时任务处理有日期过了第二天的场景
8、什么是降级，系统有没有做降级，为什么只做了熔断
9、hashmap数据结构
10、数据库双写实现原理
	01: 应用先还是保持从旧库中读写数据。   02: 编写应用，通过canal将增量数据通过新的分库分表规则同时写入新库。
	03: 同时编写旧数据的迁移工具，通过新分库分表写入新库。 03: 验证数据是否一致。


电话面试：
2、equals和==的区别
	==在比较基本类型时，比较的是值，在对于引用类型时，比较的是内存地址。equals处于object类中，就是所有对象都可以重写equals方法，如果不重写的情况下，其实跟==一样比较的是内存地址，基本类型没有equals方法，他们对应的包装类有。如果重写equals的话，比较两个对象时，就会根据你对应的equals方法进行比较，如果内容相同，就返回true.
4、hashmap在存储数据的时候的操作
5、redis存储机制在项目中是如何使用的
6、在项目中如果使用double类型，怎么做比较
7、线程的几种状态
	1、初始状态：线程被构建，还没执行start方法。 2、运行状态（里面还有一个ready状态，只不过jvm帮我们隐藏了，统一展示为running状态） 3、阻塞状态：表示线程阻塞于锁 4、等待状态：线程进入等待状态，表示当前线程需要等待其他线程作出一些特定动作（唤醒或中断）5、超时等待状态（可以指定时间自行返回） 5、终止状态：表示线程运行结束
8、创建线程的几种方式
	1、继承thread类。  2、实现runnable接口。 3、实现callable接口，结合future实现。  4、通过线程池创建线程
	其实只有两种创建方式，thread，和runnable， 其实底层都是创建一个线程，然后执行里面对应的run方法。


晚上8点半面试：（虐了）
1、rocketMQ如何防止消息不丢失 (生产者的事务消息机制)
	从几个方面考虑，Producer 发送消息，Broker 保存消息，Consumer 消费消息，Broker 主从切换；
	维度1:同步发送，根据返回的状态码，可以做消息重试，这里设置的重试次数是3。SEND_OK，FLUSH_DISK_TIMEOUT（消息发送成功但是消息刷盘超时），FLUSH_SLAVE_TIMEOUT（消息发送成功但是消息同步到 slave 	节点时超时），SLAVE_NOT_AVAILABLE（消息发送成功但是 broker 的 slave 节点不可用）
	维度2:异步发送，重写回调函数，回调函数捕获到 Exception 时表示发送失败，这时可以进行重试，这里设置的重试次数是 3。
	维度 3：刷盘策略，异步刷盘（默认）， 同步刷盘（默认5s没成功，就返回FLUSH_DISK_TIMEOUT）
	维度 4：Broker 多副本和高可用（一主多从部署）,salve的同步复制和异步复制
	维度 5：消息确认，如果 Consumer 消费成功，返回 CONSUME_SUCCESS，提交 offset 并从 Broker 拉取下一批消息。
	维度 6：Consumer 重试，返回 RECONSUME_LATER，Broker 收到这个响应后，会把这条消息放入重试队列，重新发送给 Consumer。Consumer可以把消息存入本地，给 Broker 返回CONSUME_SUCCESS 来结束重试。
	维度7：事务消息，Producer 发送 half 消息，Broker 先把消息写入 topic 是 RMQ_SYS_TRANS_HALF_TOPIC 的队列，之后给 Producer 返回成功；然后Producer 执行本地事务，成功后给 Broker发送 commit 命令（本地事务执行失败则发送 rollback）；Broker 收到 commit 请求后把消息状态更改为成功并把消息推到真正的 topic；Consumer 拉取消息进行消费。
	维度 8：消息索引
	维度 9：极端情况（集群挂了，producer做降级，把要发送的消息保存到本地数据库或磁盘，等 RocketMQ 恢复以后再把本地消息推送出去）

	
2、mq高可用性：
	通过broker主从机制实现高可用
	消息生产的高可用：在创建topic时，把topic的多个message queue创建在多个broker组上，当一个broker组的master不可用时，生产者可以给其他broker上面继续发消息
	消费消息的高可用：不能支持配置从master读还是slave读，当master不可用或者繁忙的时候，会自动切换到slave中读，保障了消息消费的高可用
	消息存储结构： commitLog（存储消息的元数据）、ConsumerQueue（存储消息在CommitLog的索引）、indexFile(提供一种通过key或者时间区间查询消息的方法)
	刷盘机制：同步刷盘、异步刷盘（可能会造成消息丢失）
	主从复制：同步复制、异步复制（异步复制）
	producer负载均衡： producer在发送消息时，默认轮询所有queue,消息发送到不同的queue上，queue分布在不同的broker上。
	consumer负载均衡：默认的分配算法AllocateMessageQueueAveragely（每个consumer实例平均分配每个consume queue）
	消息重试：
		发送端重试
		消费端重试：对于顺序消息，进行消息重试的时候，后续消息会被阻塞。这一块监控要做好，避免后续消息阻塞
	重试队列和死信队列：
		消息失败进入重试队列
		失败后达到最大重试次数后，进入死信队列，以DLQ消费组命名	
	
3、异步方式
	spring中@async的注解， 线程池、future、mq

4、future阻塞等待
	get()方法

6、future和futuretask
	future就是一个接口，异步执行线程，一般配合excutors使用，它里面提供了get()获取结果的方法，执行时会进行阻塞，知道执行完成，除开之外它还提供了查看是否完成，取消任务等方法，相对于future,futuretask实现于runnableFuture接口，其实就是继承于Runnable, future接口，所有它拥有runnable和future的特性，他既可以被线程执行，也可以作为future获取返回值，其实本质上没什么区别

7、io流的分为几种？，能简单讲讲fileinputstreamreader嘛
	1、按照流的流向分：可以分为输入流和输出流
	2、按照操作单元划分：可以划分为字节流和字符流
	3、按照流的角色划分分为节点流和处理流（这里可以不说）
	所有IO流从4个抽象类中派生出来的：
		InputStream/Reader：所有输入流的基类，前者是字节输入流，后者是字符输入流
		OutputSteam/Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流
		缓冲操作：bufferInputStream, BufferedOutputStream、bufferedReader、bufferedWriter
		基本数据类型操作：dataInputStream、dataOutputStream
		对象序列化操作：ObjectInputStream、ObjectOutputStream
		转化控制：InputStreamReader、OutputStreamWriter
		文件操作：fileInputStream、FileOutputStream、fileReader、fileWriter
		管道操作：pipedInputStream、。。。。。。
		数组操作：ByteArrayInputStream、ByteArrayOutputStream、CharArrayReader、CharArrayWriter

	有了字节流为什么还需要字符流：
		字符流是java虚拟机将字节转换得到的，这个过程相对耗时，如果我们不知道编码类型还容易出现乱码现象。所以，IO流干脆提供了直接操作字符的接口，方便我们对字符进行流操作。对于音频、图片等媒体文件用字节流会好一点，如果涉及字符用字符流操作好一点


10、过滤器和拦截器
	两者类似，都是aop编程思想的体现，
	01: 使用范围不同，filter是servlet规范约定的，用于web程序中，拦截器可用于web,applicaiton,swing程序中
	02: 规范不同，servlet容器支持filter, 拦截器是在spring容器中，spring框架支持
	03: 使用资源不同：拦截器归spring管理，是spring中的一个组件，能使用spring中的资源，对象，如数据源，事务管理，通过ioc注入到拦截器。filter不能
	04: 深度不同：filter只在servlet前后起作用，拦截器可以深入方法前后，异常前后，具有更大的弹性。

11、api安全性

12、https拦截，https证书，https安全性
	加密方式：对称加密（key被三方获取，得到原数据data）
	非对称加密: 私钥、公钥 （反向发送时无法获取私钥）
	对称加密 + 非堆成加密 （中间人攻击）


13、api垂直越权、水平越权
14、mybatis excutor包下有哪些执行器
	simpleExecutor
	reuseExecutor
	batchExecutor
	cacheExecutor

15、future参数中timeUtil中的参数： 天、时、分、秒、毫秒、微秒、毫微秒

16、mq的顺序消息：
	producer端：producer端确保消息顺序唯一要做的事情就是发送到特定的分区，rokcetmq中通过messageQueueSelector来实现分区的选择
	consumer端：MQPullConsumer 和 MQPushConsumer, pullConsumer每次获取到的是一个MessageQueue中的消息。PullResult中的List
		msgFoundList自然和存储顺序一致，用户需要再拿到这批消息后自己保证消费的顺序。 pushConsumer方式是：先从broker单线程获取消息，然后将消息添加到processQueue中（processqueue消息是顺序的），然后消息提交到用户消费的那个consumerMessageService里面，然后comsumer在messageService里面取消费processQueue里面的消息，这个情况是顺序的

17、mq的处理大量堆积：
		mq的消费者的负载均衡，增加topic下messageQueue（前提是messgeQueue配置得比较多，增加consumer节点数量加快消息消费）
		第二种，创建一个新的topic,配置足够多的messageQueue, 把所有消费者节点转向新的topic，并紧急上线一组新的消费组，只负责消费旧的topic.		

 

19: bigdecimal如何保证精度
	 10进制转二进制精度没什么问题，bigdecimal里面有scale(记录精度信息), intCompact（记录被放大的整数信息）


20: synchronized底层实现原理（简单版）
		主要也是基于jvm中monitor指令，一个线程进入代码块之后，monitorenter操作，将monitor + 1，同一个线程可重入，第二线程来时查看monitor数量，如果次数大于0，则进行阻塞等待，
	等第一个线程执行完成之后，会执行到monitorexit这个指令，monitor次数减1，如果此时monitor为0，阻塞的第二个线程可获得monitor，然后进行一系列操作。在深入一点的话，就关乎于
	硬件底层的一个内存屏障，内存可见性，原子性操作了。在修饰方法的时候，没有monitorenter指令的，用了一个acc_synchronized标识。不过两者本质都是对monitor监视器的获取。
		synchronized的了解：
			它主要是来解决多个线程访问资源的同步性，可以保证被他修饰的方法或者代码块在执行时是只有一个线程执行的。早起版本的时候，属于重量级锁。因为底层他的监视器锁，依赖于操作系统中的一个mutex locak,所以在进行一个线程的唤醒或者说挂起的操作时，在操作系统中会有一个线程切换的操作嘛，这个时候就是将里面的用户态转到内核态，这个状态转换成本时间相对比较长的。jdk6对起进行了一个大改革，大量的优化，引入了自旋锁、偏向锁、轻量级锁，然后对其进行锁升级，锁降级这些来减少锁操作的开销。
		synchronized跟volatile的区别：
			两者应该是互补，volatile是线程同步的轻量级实现，性能比sync好嘛，但是它只能修饰变量，sync可以修饰方法和代码块。2、volatile能保证数据的可见性，不能保证原子性。sync两者都能保证。3、volatile主要用来解决多个线程之间变量的可见性的嘛。sync主要处理访问资源的同步性。	



21: cas底层是基于什么（简单版）
	compare and set， 类似于atomicInteger这种，底层都是基于cas实现，在多线程自增中，线程1拿到存在内存旧值中值，在自增前先比较旧值，如果发现值一样的，就进行自增操作，此时操作成功，线程二在拿到旧值后发现跟原先需要自增的值不一致，cas就会自旋锁，一直等待内存的值为一致时，就行自增。

22: concurrentHashMap底层原理（简单版）
	它处于Java.util.concurrent并发包下，是线程安全的，在jdk1.7中，主要实现是以分为多个数组，进行加锁，这种叫分段锁，在多线程下同时插入在同一个加锁的数组中，会被锁住，但是在不同的分段的数组中操作时，他可以进行并行的插入数据，这个分段锁在segment, 继承于reentrantLock, 所以它是一个可重入锁，扮演锁的角色。在jdk1.8中对其进行一个优化，不采用多个数组加锁的形式，还是使用一个数组，对每个数组进行cas操作，多线程插入时如果不在同一个数组中插入的话，是可以并行操作的，如果插入的是同一个数组，会进行cas操作，线程1如果先拿到，发现里面值为null, 写入，线程2进来时发现有值，就会进行一个自旋操作，直到上一个线程修改完成，线程2比较内存值相同。数组里面不是还有链表 + 红黑树的转换嘛，这个时候 java8里面在其加入了synchronized的锁，保证其插入链表时的线程安全性。
		concurrentHashMap 和HashTable的区别：
			底层数据结构不同，1.7/1.8采用不同的方式，hashtable类似1.7hashmap中的数据结构
			实现线程方式不同，hashtable非常硬核，直接加入synchronized锁


23: AQS是啥，aqs实现原理是啥
	抽象队列同步器，一个用来构建锁和同步器的框架。我们常用的一些同步器，比如说ReentrantLock，semaphore,futureTask都是基于AQS. 它里面思想就是当共享资源被占用时，有一套线程阻塞等待以及线程唤醒时锁分配的一个机制。好像是用那个CLH队列锁实现的，就是将获取不到锁的线程加入到队列中。	用一个int成员变量state表示同步状态。里面有一个内置的fifo队列获取资源排队工作。
		AQS对资源的共享方式：
			exclusive(独占)： 只有一个线程能执行，如reentrantLock. 里面又可以设置公平锁还是非公平锁。
			share(共享)： 多个线程同时执行，countDownLatch, semaphore, cyclicBarrier, readWriteLock
	01: AQS使用到的设计模式？
		模版设计模式
	02: 如何修改和访问同步器的状态
		getState: 获取当前同步状态   setState: 设置当前同步状态。 compareAndSetState: 使用cas设置当前状态，该方法保证状态设置的原子性
	03: 提供哪些模版方法：
		1、Acquire(): 独占锁获取同步状态。	2、acquireShared(): 获取共享锁的同步状态。 3、release： 释放同步状态，并通知同步器，唤醒等待队列第一个节点的线程  4、releaseShare: 释放同步状态
	04: aqs同步队列的数据结构
		1、有虚拟头尾节点的双向链表。
		当前线程获取同步状态失败，同步器将当前线程机等待状态等信息构成一个node节点加入队列，放在队尾，同步器重新设置尾节点
		加入队列中，会阻塞当前线程
		同步状态被释放并且同步器重新设置首节点，同步器唤醒等待队列中第一个节点，让其获取同步状态。
	05：同步器如何设置尾节点的
		当多个线程同一时刻获取独占锁时，多个线程同时竞争末尾的资源，出现线程安全问题，为了解决这个问题，提供了compareAndSetTail方法，利用cas的操作，保证只有一个线程设置成尾节点，然后设置完成之后才进行下一个尾节点设置。
	06: 同步器如何设置首节点
		不需要保证线程安全，因为不会存在多个线程竞争的问题，在设置头节点时，之后获取到对应的同步状态线程才能设置，因为在获取这个步骤已经保证到只有一个线程拿到，所以不存在线程安全的问题。
	07: 为什么只能其前驱节点是头节点，才会尝试获取同步
		拥有同步状态的线程释放同步状态的时候，唤醒后继节点，为维护fifo原则，后继节点唤醒后需检查自己的前驱节点是不是头节点。
	08: 独占锁和共享锁有什么区别
		1、共享锁是多个线程同时拥有，在获取同步状态是否成功，共享锁是通过判断返回值是否大于0，独占锁通过true/false判断。
		2、独占锁释放同步状态不用关心线程安全问题，只有一个线程释放。共享锁是多个线程同时拥有，需要保证安全性，通过cas自旋来实现。
				

	

24: hashCode与equals
	hashCode的作用就是获取hash码，返回int类型，也就是确定该hash码在hash表中的位置，定义在object类中，任何类都包含hashCode函数

25: 序列化时有些字段不想被序列化
	使用transient关键字，作用是阻止实例中那些用此关键字修饰的变量序列化,反序列化时，不会被持久化和恢复,只能修饰变量值，不能修饰类和方法

26、try-catch-finally
	用于捕获异常，其后可接零个或多个catch块，没有的话，必须要finally块。catch，用于处理try语句块里面包含的异常。finally无论捕获异常什么的，都会被执行，当遇到return语句，会在方法返回前被执行。finally什么情况下不被执行：1、finally块第一行代码处理异常。2、在前面执行了system.exit语句，3。线程死亡 4、关闭cpu

27、BIO，NIO，AIO有什么区别
	BIO: 同步阻塞IO模式，数据的读取写入必须阻塞在一个线程内等待完成。活动连接数不是特别高情况下，这种还是不错的，可以让每一个连接专注于自己的IO并且编程模型简单，也不用过多考虑系统的过载、限流等问题。
	NIO: NIO是同步非阻塞的IO模型，Java1.4引入，提供了channel、selector、buffer等抽象。对应模型中的Socket和serverSocket相对应的SocketChannel和serverSocketChannel两种不同套接字的实现。也是可以支持阻塞和非阻塞两种模式。非阻塞模式下对于高负载、高并发的应用，应使用NIO非阻塞模式来开发
	AIO：异步非阻塞IO模型，它是基于事件和回调机制实现的。也就是应用操作之后直接返回。不会阻塞，后台完成之后操作系统会通知响应线程进行后续的操作。

28、线程、进程区别：
	一个进程包含多个线程，在java中，每个线程都有自己的程序计数器，虚拟机栈，本地方法栈，线程是进程的更小的划分单位。各个进程是独立的，而各个线程不一定，因为同一进程中的线程可能会相互影响。
		程序计数器为什么私有？
			1、字节码解释器通过改变程序计数器依次来读取指令，实现代码的流程控制。
			2、多线程下，程序计数器记录当前线程执行位置，当线程切换回来可以继续执行（主要还是为了这）
		虚拟机栈和本地方法栈为什么私有：
			1、为了保证线程中的局部变量不被别的线程访问到

	进程的通信机制：


29、线程相关问题
		线程之间的通信方式：
		（主要用于线程同步，所以没有像进程通信用于数据交换的通信机制）
			锁机制：互斥锁、条件变量、读写锁
				wait/notify、volatile
			信号量机制
				semapphore
			信号机制
				类似进程中的信号处理


		线程上下文切换：
			每个线程在cpu执行时分配的有时间片，时间片一到，线程处于就绪状态，cpu进行切换到下一个线程执行，等轮换执行到这个线程时，重新获取时间片执行。官方话语叫：任务从保存到再加载的过程就是一次上下文切换。

		线程死锁：
			两个线程持有不同的资源，两个线程都想要获取双方的资源，相互等待，一直无法等待对方释放锁，一直卡着，就会产生死锁。产生死锁的四个条件：1、互斥条件。2、请求与保持条件。3、不剥夺条件 4、循环等待条件

		sleep()和wait()区别：
			sleep方法没有释放锁，wait方法释放锁

		为什么不能直接调用run方法，必须要调start方法：
			线程new出来，处于新建状态，此时执行start方法，会启动一个线程，然后这个线程进入线程的下一个状态，就绪（readt）状态，就是running嘛，其实才开始真正的多线程工作。如果直接执行run, 会把他当作普通方法执行。

18、线程池的7大核心参数介绍：
		corePoolSize：线程池的常驻核心线程数
		maximumPoolSize: 线程池能够容纳同时执行的最大线程数，必须大于1
		keepAliveTime： 多余线程的存活时间
		unit：keepAliveTime的单位
		workQueue: 里面放了被提交但是尚未执行的任务
		threadFactory: 表示线程池中工作线程的线程工厂，用于创建线程
		handler: 拒绝策略	
	  01: 为什么是先添加队列而不是先添加最大线程？
	  	  在创建新的线程的时候，是需要获取全局锁的，这个时候其他线程就得阻塞，影响了整体效率。
	  02: 线程池中阻塞对列有什么作用？
	  	阻塞队列自带阻塞和唤醒的功能，不需要额外处理，无任务执行时，线程池利用阻塞队列的take方法挂起，从而维持核心线程的存活，不至于一直占用CPU资源	
	  03: jdk中4中拒绝策略： AbortPolicy（直接抛异常），callerRunsPolicy(调节机制，不会抛弃任务，也不会跑出异常，将任务回退)，DiscardPolicy：（抛弃队列中等待最久的任务，将当前人加入队列，提交），DiscardOldestPolicy，默默丢弃无法处理的任务，不允任何受理，不抛异常。 
	  04: 线程池中阻塞队列的作用，为什么不采用其他的队列：  一般队列有缓冲区，超出缓冲长度，无法保留当前任务，阻塞队列可以阻塞保留；阻塞队列可以保证队列阻塞获取任务的线程，有wait，可以等待，释放cpu资源  		

30: threadLocal
		实现每个线程都有专属的本地变量，每个线程绑定自己的值。访问这个变量的每个线程都有这个变量的本地副本。通过set、get获取默认值。
	实现原理就是线程Thread类里面有两个变量，两个都是threadLocalMap类型，就是ThreadLocal类里面的一个hashMap,默认的情况下两个变量都是为空。只有当调用threadLocal的get、set方法的时候才会对其进行一个赴值。
		threadLocal内存泄漏了解一下？
			threadLocal使用的key是一个弱引用，value却是强引用。所以threadLocal没有外部强依赖的情况下，在垃圾回收的时候key会被清理掉的。value不会，如果我们不做任何措施的话，value就永远不能被gc。这个时候会产生内存泄漏。所以使用完threadLocal,最好手动调用remove方法。


31: 线程池
	为什么要使用线程池：
		1、降低线程消耗：就是反复利用已创建线程，从而来降低线程的创建和销毁嘛
		2、提高响应速度：当任务来的时候，不需要等待，直接拿来用就好了
		3、提高线程的可管理性： 线程还是宝贵的，不能无限制的创建，使用线程池能够起到一个统一的分配，调优、监控等。

	如何创建线程池
		阿里巴巴规范约定，不允许使用executors创建，需要用threadPoolExecutor创建，这样处理能让写的同学明确线程池的运行规则。使用excutors的弊端：1、FixedThreadPool和singleThreadExcutor: 允许请求的队列长度为integer.maxValue。可能会堆积大量请求。cachedThreadPool和scheduledThreadPool: 允许创建的线程为max_value, 可能创建大量线程。
		1、FixedThreadPool： 固定数量的线程池，数量始终不变，任务过来，有空闲就立刻提交，不然就暂存到一个任务队列中，有空闲就执行。
		2、sigleThreadExecutor: 返回只有一个线程的线程池。多余任务过来，也是保存在任务队列中，线程空闲后，按照fifo的规则执行。
		3、cachedThreadPool: 返回一个根据实际情况调整数量的线程池，线程数量不确定，又可复用线程优先使用。均在工作时，就创建新的线程处理任务。

	线程池执行原理：
		1、提交任务，核心线程数是否满，没满就创建线程，满了就去看等待队列满没，没满就加入队列，满了就去看线程最大承受满没，没满就创建，满了就按照对应的淘汰策略执行。

	线程池生命周期：
		1、用户无法显示设置，伴随线程池的运行，内部进行维护，有一个atomicInteger的ctl变量表示运行状态，前三位表示运行状态，后29位表示线程数量。用同一个变量保存两个值，不必维护两者的一致，去占用一个锁资源。2、总共有5种状态：01: running(运行状态，能够接受新提交的任务，并且能够处理阻塞队列中的任务)，02：shutdown(关闭状态，不在接受新提交的任务，能继续处理阻塞队列中的任务) 03: stop(停止状态，不接受新任务，不处理队列中的任务，中断正在处理的任务) 04:tidying（整理状态，所有任务终止，有效线程为0） 05: terminated（终止状态）

	线程池的复用机制：
		从队列中读取，就是从workerQueue执行，每一个都是一个Worker,Worker对象实现runnable接口，实现其run方法，这个run方法里面让每个定义的线程去执行一个循环，在循环代码中，判断是否有任务待执行，因此线程数不会增加。循环里面有一个getTask方法，就是从阻塞队列里面拿任务出来	


32: atomic类
	总共分为4类，1、基本类型，AtomicInteger，AtomicLong，AtomicBoolean 2、数组类型 AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray
	2、引⽤类型： AtomicReference、AtomicStampedReference、AtomicMarkableReference 3、对象的属性修改类型

33: spring面试题
	1、spring ioc 和 aop理解
		IOC是一种设计思想，将原本程序中需要手动创建对象的控制权，交给spring管理。简化我们其中的开发，从复杂的依赖关系中解放出来。初始化过程：从xml读取，resource解析，再有beandefinition注册到beanfactory.
		AOP能够将与那些业务无关的，却跟业务模块共同使用相同的逻辑进行一个封装，减少系统的重复代码，以及降低耦合性。aop基于的也是动态代理，对于代理的对象，如果实现了接口用的jdk的动态代理，没有实现接口的对象，就是用cglib生成一个被代理对象的子类作为代理。

	2、spring bean
		bean的作用域有哪些：
			sigleton: 唯一bean实例，spring中bean默认都是单例的
			prototype： 每次请求都会创建一个新的bean实例,有状态的bean可以用prototype,无状态用sigleton
			request: 每⼀次HTTP请求都会产⽣⼀个新的bean，该bean仅在当前HTTP request内有效。
			session: 每⼀次HTTP请求都会产⽣⼀个新的 bean，该bean仅在当前 HTTP session 内有效
			global-session: 全局session作用域，spring5已经弃用

		spring 单例bean的线程安全问题？
			存在多线程问题，多个线程操作同一个对象的时候，会对对象的非静态成员变量的写操作存在线程安全问题。
			常见两种解决方案：
				1、bean对象中尽量不去定义可变的成员变量
				2、如果有这方面的考虑的话，可以定义一个threadLocal成员变量，将需要可变的成员变量保存在threadLocal中。

		@component和@bean有什么区别
			1、作用对象不同，一个在类上，一个注解作用于方法上
			2、component通过类路径扫描自动装配到spirng中的，@bean通常标注在方法上，告诉spring这个类的实例，需要用它时直接注入就好；

		一个类声明为spring中的bean注解有哪些：
			1、@autowired注解自动装配bean, 还有另外通用的4个。

		spring的生命周期：
			1、找到bean定义,说白了就是实例化 2、依赖注入。对实例化的bean进行配置，利用java反射的api创建bean实例 3、set定义的属性值，设置beanname，就是bean定义的id
			4、BeanFactoryAware实现，如果有实现这个接口，就调用setBeanFactory方法，获取其他的bean 5、applicationContextAware看是否实现，实现就去调用setApplicationContext,注入spring上下文  6、加载PostProcesserbeforeinit进行前置处理 7、检查是否有配置init-method ,有就调 用 ，没有就后置处理 8，使用中，使用完后根据配置的destroy方法，进行响应的销毁。

		spring ioc实现方式：
			具体整体的代码没了解过，但是spring中的两个核心接口，beanfactory和applicationContext了解过一点点，所有的bean注册都基于beanfactory, 这是spring的一个顶层接口，applicationContext是它的子接口，由它派生过来的，，其中beanfactory最主要的方法就是getBean,从容器返回特定名称。beanFactroy的功能通过其他的接口进行一个不断扩展,比如说beanDefinitionRegistry，它里面描述了bean的配置信息，beanDefination对象向容器，提供向容器手动注册beanDefination对象, beanfactory实现包括bean配置文件，管理bean的加载，实例化，控制bean的生命周期，维护bean之间的依赖关系这些的。applicaiotnContext作为beanFactory的派生，具有beanFactory的功能，并提供了更完整的功能，比如统一的资源文件访问方式，提供监听器注册bean事件。

		beanfactory和applicationContext的区别：
			applicaitonContext是beanfactory的派生，除具有beanfactory的功能外，还有具有监听注册bean事件，统一的资源访问方式功能。在加载方式上，beanfactory采用延迟加载的方式，就是用到了才去加载bean,applicationContext是一次性创建所有的bean,能在容器启动前发现错误。相比较下，唯一不足的就是ac占用内存空间，启动较慢。在创建方式上：beanfactory以编程的方式创建，applicaitonContext以声明方式创建，比如contextLoader.

		spring依赖注入：
			容器动态的将依赖关系的对象注入到应用系统的各个组件中嘛。这点好处就是将控制权全权的交给容器负责。依赖注入目前主要使用的方式：构造器注入，setter注入	。在选用时，强制依赖选择构造器实现，可选依赖使用setter. 还有两种 静态工厂注入，实例工厂注入

		spring装配方式：
			1、spring装配方式分为手动和自动，手动包括xml, 构造方法，setter, 现在大部分用@autowired注解进行自动装配	

	3、spring特点
		轻量级，控制反转，面向切面，容器，框架集合

	4、spring AOP面试题目
		01: 使用场景：权限，统一异常统一处理，接口日志打印，事务，统一数据处理。

   		02: 核心概念：切面，横切关注点(对哪些方法进行拦截)，连接点(joinPoint, 被拦截的点，在spring中拦截的是方法)，切入点(对连接点进行拦截的定义)
   		，通知（advice，就是拦截时执行的代码，有前置，后置，异常，最终，环绕通知五类），目标对象（代理的目标对象），织入（将切面应用到目标对象并导致代理对象创建的过程）

   		03: AOP代理，主要分为静态代理和动态代理，静态代理是在编译阶段生成AOP代理类，编译期增强。动态代理指的就是运行的时候临时生成aop对象，包含对目标对象的全部方法，对特定切点做增强处理，回调原来的对象。对接口使用的是jdk的动态代理，其余的使用的cglib 

   		04:AOP增强执行顺序，环绕前置，前置，target方法执行，环绕后置，后置，最终。

	5、springmvc
		  在遥远的Java web mode2时代，主要用的就是servlet + jsp, 通过controller返回数据展示给jsp中，这种模式会产生大量的冗余代码，重复造轮子，很多没有必要的代码，所以对程序的可维护性和复用性都比较低。所以mvc模式这个时候出来了，springmvc天生跟spring框架集成，将后端分为service层，dao层，entity层，controller层。

		  springmvc的工作原理：
		  	 1、浏览器发起请求，请求到DispatchServlet。2、DispathchServlet根据请求信息调用HandlerMapping, 对请求进行解析。 3、解析之后会到Handler,就是controller嘛，由HandlerAdapter适配器进行处理 4、HandlerAdapter会根据Handler调用真正处理器进行请求，处理相关的业务逻辑。4、处理完之后返回modelAndView对象，然后viewResolver根据逻辑返回的view找到对应的view层，再有dispatchServelter把model返回view。再渲染到前端。

		  spring框架中运用的设计模式？
		  	1、工厂模式： beanFactory, applicaitonContext创建bean对象
		  	2、单例模式： spring中bean默认就是单例的
		  	3、代理模式：典型的就是spirng aop功能的实现。
		  	4、观察者模式： spirng事件驱动模型
		  	5、适配器模式：handerAdapter适配controller

		  	

	4、spirng中的事务	  	
		1、编程式事务 2、声明式事务
		事务的传播机制：
			支持当前事务： 
				PROPAGATION_REQUIRED： 如果存在当前事务，加入该事务，没有就创建
				PROPAGATION_SUPPORTS：存在当前事务，加入该事务，不存在以非事务运行
				MANDATORY： 存在事务就加入，不存在抛出异常
			不支持当前事务：
				REQUIRES_NEW：创建一个新的事务，当前存在就将当前事务挂起
				NOT_SUPPORTED: 非事务运行，如果有当前事务，就将事务挂起
				NEEVER: 非事务运行，存在当前事务，就抛出异常	
			嵌套事务：
				nested：存在当前事务，就创建一个事务作为当前事务的嵌套事务。当前没事务，就等价于REQUIRED

	5、spring获取bean的几种方式
		01: 使用BeanFactory直接获取，通过XmlBeanFactory获取，但是类已经废弃，不推荐
		02: 获取applicationContext对象，通过ClassPathXmlApplicationContext获取（必须）
		03: 继承自抽象类ApplicationObjectSupport
		04: 使用Spring提供的工具类WebApplicationContextUtils
		05: 实现ApplicationContextAware接口（必须）
		06；使用ContextLoader提供的getCurrentWebApplicationContext方法，得到对象也是WebApplicationContext

	6、spring事务失效场景
		01: 数据库引擎不支持事务，比如MyISAM
		02: 入口方法不是public, springAop特性决定的，private方法事务不能切入
		03: Spring事务管理默认只支持运行期异常进行回滚
		04: 没有启用事务和切面
		05: 类是否被正确代理
		06: 默认情况下，只有来自外部的方法调用才会被AOP代理捕获，也就是，类内部方法调用本类内部的其他方法并不会引起事务行为，即使被调用方法使用@Transactional注解进行修饰。
		06:业务和事务要在同一个线程，否则事务也不生效，比如



mysql面试题：

	什么是回表查询：
		1、innoDB有两个索引类型嘛，一个是聚集索引，一个是普通索引，聚集索引叶子结点存储行记录，innoDB必须要有，且只有一个，如果定义主键，主键就是聚集索引，否则唯一键。普通索引的叶子结点存储的是主键值，普通索引无法定位到行信息，所以先去普通索引树里面找到主键值，然后再定位到聚集索引上。这就是回表查询。

	什么是覆盖索引：
		1、只需要在一颗索引树上找到SQL所需的列数据，无需回表。就是将查询的字段，建立到组合索引上。

	mysql的执行计划分析：
		1、id: 序列号，相同顺序由上至下，不同时，id值越大优先级越高，越先被执行。
		2、select_type: 查询数据的操作，01: simple(简单查询) 02:primary(包含复杂的子查询，最外层查询标记为该值) 03: subquery(在select或者where包含子查询) 04: derived(在from列表包含的子查询，结果放在临时表) 05:union(出现在union的时候)
		06: union result(从union表获取结果)	
		3、table: 显示该行数据是关于哪张表
		4、partitions： 匹配到的分区
		5、type：表的连接类型，其值、性能由高到低排列如下。
			01:system(表只有一行记录，相当于系统表)
			02: const(通过索引一次找到，只匹配一行数据)
			03:eq_ref(唯一性索引扫描，用于主键或唯一索引扫描)
			04:ref(非唯一索引扫描)
			05: range(检索给定范围的行，用一个索引检索行，比如between, > , <)
			06: index(只遍历索引树)
			07: all(全表扫描)
		6、possible_keys：指出mysql使用哪个索引再该表找出记录，为null表示没走索引
		7、key: 实际使用的索引，为null没走索引
		8、key_len: 索引使用的字节数，越短越好
		9、ref： 该表索引关联到哪张表 10、rows(估算出读取的行数，数值越小越好) 11、extra：十分重要的额外信息，using filesort，使用外部的索引排序，出现说明sql该优化了。using tempory，使用到了临时表，说明该优化了

	事务的四大特性：原子性、一致性、隔离性、持久性	
	
	四大特性实现原理：原子性(undo log实现，事务执行过程中出错或者rollback, 通过undo log返回事务开始的状态)，持久性(redo log实现，系统奔溃后，通过redo log进行数据恢复) ,使事务隔离开），一致性（通过回滚、恢复，以及并发情况下的隔离性，从而实现一致性）

	事务隔离级别：
		读未提交：最低级别，任何情况无法保证
		读已提交：避免脏读的发生
		可重复性读：可避免脏读，不可重复读发生
		串行化：可避免脏读，不可重复读，幻读

	什么是幻读、不可重复读、幻读？
		1、脏读：脏读指读到其他事务未提交的数据。 2、不可重复读：指的是一个事务内，最开始读到的数据和事务结束前任意时刻读到的同一批数据出现不一致的情况。3、幻读：侧重于是在select操作得到的结果数据无法支撑后续的业务操作。更为具体一点：select记录是否存在，不存在，插入此数据，执行insert时发现此记录存在，无法插入，这就是幻读。

	datetime和timestamp区别：
		datetime范围1001-9999年，timestamp范围是1970-2038年，2、datetime存储时间跟时区无关，timestamp存储时间跟时区有关。3、datetime存储空间8个字节，timestamp存储空间为4个字节。 4、datetime默认为null，timestamp默认不为空，为当前时间

	varchar和char有什么区别：
		char是一个定长字段，varchar是变长字段，申请的是最大长度，占用空间是实际字符串+1.检索效率char > varchar

	count(1)、count(*)、count(列名)的区别
		count(*) 包括了所有的列，相当于行数，在统计结果时，不会忽略列值null
		count(1) 忽略所有列，用1代表码行，不会忽略列值
		count(列名) 包括列名那一列，统计结果时，忽略列值为空。

	exist和in的区别？
		使用in时先执行子查询，然后在查主表，而exist先查主表，在查子查询。如果是小表驱动大表，应该用in，反之主表记录少，子查询大，有索引时用exist.

	union和union all的区别？
		union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序
		union all: 对两个结果集进行并集操作，包括重复行，不进行排序

	group by和distinct的区别？
		distinct先获取结果集，再去重。group by基于key先分组，再返回结果，都能用到索引，执行效率没什么差别
		group by语义更为清晰、灵活，可以对数据进行复杂处理，配合having进行行过滤，然后再去计算。

	blob和text区别
		blob用于存储二进制，text存储大字符串

	innoDB和myISAM的区别
		1、事务支持：myISAM不支持事务，而InnoDB支持。2、表锁差异：myISAM只支持表级锁，InnoDB只支持事务和行级锁。行锁提高了并发操作的性能，但是只有在索引上才使用行锁 3、索引结构：myISAM和Innodb都用B+树，myisam叶子结点存放的是数据记录的地址，即索引文件和数据文件是分离的，这种叫非聚集索引。innoDB的数据文件本身也是索引文件，叶结点保存了完整的数据记录。索引key为主键，这种事聚集索引。 4、表主键：myisam允许没有任何索引和主键存在，innodb必须要一个主键索引。5、外键：myisam不支持

	bin log/redo log/undo log是什么？
		三种不同级别的日志，bin log在服务层实现，redo log、undo log是在引擎层实现，innodb引擎独有的，主要与事务有关
			big log: mysql数据库级别的文件，记录了除select、show之外的执行修改的所有操作。实际场景中，主要用主从复制 和 数据恢复，主从复制是master开启binlog,   、然后发送各个从结点，达到主从数据一致. 数据恢复主要通过mysqlbinlog工具进行恢复。
			redo log: redo log记录要更新的数据，如果数据提交成功，不会立即同步到磁盘，先记录到redo log中，等待合适的时机在刷盘，实现事务的持久性。如果没有这个，每次提交旧刷盘,性能会比较慢，因为innodb是以页为单位进行磁盘交互。
			undo log: undo log用于数据撤回操作，保留记录修改前的内容。通过此可实现回滚，并根据undo log回溯到某个特定版本的数据，实现mvcc

	bin log和redo log的区别
		1、bin log记录所有日志记录，redo log只记录本身innodb自身的事务日志 2、bin log在事务提交前写入磁盘，一个事务只写一次；而在事务进行过程，会有redo log不断写入
		3、bin log是逻辑日志，记录sql的原始逻辑，redo log是物理日志，记录在某个数据页做了什么修改

	数据库的三大范式：
		第一：数据表的每一列不可在拆分
		第二：非主键列完全依赖主键，不能依赖主键的一部分
		第三；非主键列只依赖于主键，而不依赖于其他非主键

	主键用自增id还是uuid
		自增id,innodb使用的是b+树，叶子结点用链表连起来的，如果使用自增ID，只需要连续往后排，查的时候能够更好的查询，而uuid因为大小不确定，插入时数据移动，可能会产生一些内存碎片，导致插入性能下降

	超大分页怎么处理
		id优化：如果是自增id这种， select * from user where id>1000000 limit 100
		用覆盖索引优化：  select * from table where id in (select id from table where age > 20 limit 1000000,10)

	日常开发怎么优化sql：
		添加合适的索引：对作为查询条件和order by字段建立索引，多个查询字段建组合索引，索引控制在5个以内
		优化表结构：01: 数字型字段优于字符串类型 02:数据类型更小更好 03:尽量使用not null
		优化查询语句：01: 分析语句，是否加载没必要字段 02: 分析sql执行计划 03: sql复杂，优化sql结构	 04: 表数据量太大，考虑分表

	索引场景什么时候失效：
		1、条件中有or, 想让or生效，条件中的每列都要加索引
		2、多列索引，如果没使用第一部分，不会使用索引
		3、like查询以%开头
		4、列类型是字符串，查询时用其他的类型代替
		5、如果数据量不是特别大，mysql优化器认为全表扫比索引快，则不会使用。

	左、右、内连接的区别：
		01: left join 返回包括左表中的所有记录和右表中连接字段相等的记录。 02: right join返回包括右表中的所有记录和左表中连接字段相等的记录。 03: inner join 只返回两个表中连接字段相等的行

	如果防止sql注入：
		01: 校验参数的合法性，比如正则，特殊符号判断啥的。02: 对进入数据库的特殊字符进行转义处理，或编码转换 03:预编译sql，参数化查询方式	，避免sql拼接  04:发布前利用工具进行sql注入检测  05:sql相关报错信息不要暴露到页面上



JVM相关面试题：
	1、class.forName和classLoader的区别：
		都是对类进行加载，forname除了加载到jvm中，还会对类进行解释，执行类中的static块。loader知识讲class文件加入到jvm中
		Class.forName()得到的class是已经初始化完成的。 Classloader.loaderClass得到的class是还没有链接的（就是没有校验，准备，解析	）。

	2、什么是jvm?
		jvm是运行在Java代码的假想计算机，包括一套字节码指令集，一组寄存器，一个栈，一个垃圾回收，堆，和一个存储方法域

	3、jvm后台运行的系统线程主要有几个？
		01: 虚拟机线程。 02: 周期性任务线程。 03: GC线程。 04: 编译器线程。 05: 信号分发线程。	

	4、	介绍下堆？
		它是被线程共享的一块内存区域，创建的对象和数据都保存在Java堆内存中，也是垃圾收集器进行垃圾收集最重要的内存区域。现在采用分代手机算法，因此Java堆从gc角度可以分为，新生代和老年代。
		
	5、jvm有哪一个内存区域？
		堆、永久代、栈，Java8之后将永久代去除，永久代中的类信息放入metaspace中，存储在直接内存中，常量池则放到堆中。
	
	6、jvm如何运行？对象如何分配？
		tomcat打成的war包，由类加载器进行加载，加载完成会把类信息放入metaspace中，spring通过反射创建对应bean实例，把对应bean信息放入到堆内存中，此时用户请求线程过来，会分配一个独享内存空间，包括栈内存，方法已经逐步压栈，对象实例在堆内存中创建，栈帧存储对应引用地址，方法执行完成之后逐步出栈。
		
	7、jvm在什么场景下会进行垃圾回收？
		堆内存采用分代策略，分为年轻代和老年代，年轻代分为Eden，survival to, survival from, 比例是8:1:1，当eden区满了的时候，会触发younggc。将局部变量或者静态变量没有引用关系的对象进行一个垃圾回收。
	
	8、jvm的年轻代垃圾回收算法？对象什么时候转移到老年代？
		在触发young gc之后，因为年轻代的一般执行非常快，存活的对象比较少，eden区会进行复制算法，将存活的对象复制到survival to中，第二次gc的时候将两个Eden和survival to存活的对象复制到survival from中，三个协调合作，进行垃圾回收。
		然后对于一些经过多次young gc也能存活下来的对象，或者在开始创建时是一个较大的对象，会转移至老年代中。
	
	9、老年代得垃圾回收算法	
		因为老年代对象存活时间比较久，且存在大对象，所以不适合复制算法。所以有了标记-清除算法，先将不可用对象进行标记，然后清除对应标记得对象，但是因为对象在老年代分布不均，标记-清除可能会出现内存碎片得情况。所以使用标记-整理算法，在标记-清除上进行改进。在标记完成之后，将标记得对象进行压缩，压到另外一个
		内存空间中，然后统一清除，解决内存碎片得问题。
	
	10、垃圾回收器有哪些
		在jdk1.8及之前都是采用parnew + cms的组合，1.9之后使用G1收集器。parnew主要用于年轻代的垃圾回收，采用多线程收集，里面就是复制算法，把存活对象标记后复制到s1或者s2区域，然后有多个线程，并发处理掉eden区的垃圾对象。cms为了优化stop the world, 因为java在垃圾回收的时候会将系统置为不可用，
		所以cms采用分阶段的方式，分为初始阶段，并发阶段，并发清理，它是为了让工作现场尽可能的与垃圾回收同时运行。cms里面采用标记-清除算法，将标记的对象清理掉后再整理，将存活对象压缩到一块，避免内存碎片的发生。
		

		


springBoot相关面试题：
	1、什么是springboot: 	spring开源组织的子项目，号称是spring组件一站式解决方案，其简化了spring的难度，抛去里面繁琐的配置，提供内置启动器，快速上手。
	2、为什么要springboot： 快速开发，快速整合，配置简化，内嵌服务器
	3、springboot与cloud区别： springboot是快速开发spring框架，cloud是完整的微服务框架，cloud依赖于springboot
	4、springboot有哪些优点：
		01: 容易上手，为spring提供一个更快、更简单的开发框架。  02: 开箱即用，原理繁琐配置。  03: 提供各种通用的非业务功能。  04: 使各个方面变简单了，如配置，部署，监控

	5、核心注解：启动类上面的@springBootApplication, 主要由以下三个注解组成：@SpringBootConfiguration、@enableAutoConfiguration、@ComponentScan

	6、springboot starter的原理：启动时根据注解自动去maven中读取每个starter中的spring.factoires文件，该文件配置了所有需要创建spring容器的bean，然后自动降注入springContext

	7、@Configuration和@Component的区别
		configuration在被spring解析的时候，所有带@bean注解的方法都会被动态代理，所以产生的都是同一个实例。其实本质上还是@component。@compent在加载时没用到cglib的代理，所以里面配置bean时，返回对象不是同一实例。 	
	
	

redis相关面试题：
	redis优缺点：
		优点：01: 读写性能优异。 02: 支持数据持久化。03:支持事务。04: 数据结构丰富。05: 支持主从复制 06: 里面丰富的特性：缓存过期策略等
		缺点：01: 容量受物理内存限制。02：不具备自动容错和恢复。 03: 主机宕机，主从同步数据不及时，可能数据丢失。 04：redis难支持在线扩容

	为什么用redis, 不用map/guava
		缓存分为本地和分布式缓存。里面map/guava实现本地缓存，特点是轻量快速，声明随着jvm销毁而结束。
		redis或memcached称为分布式缓存。有单独的机器部署，可以保证一些高可用场景的使用。缺点是程序设计结构上复杂。

	redis为什么这么快
		01:完全基于内存  02: 数据结构简单。03:采用单线程，避免上下文切换 04:使用多路I/O复用，非阻塞IO。

	redis的5中数据类型：string、 list、 set、 zset、 hash
	
	redis持久化机制：
		RDB和AOF机制
			RDB是默认的持久化方式。按照一定时间将内存数据快照到硬盘中。文件已dump.rdb。通过save命令定义快照周期。优点：只有一个文件dump.rdb,方便持久化。性能最大化，fork子进程完成写操作，主进程处理命令，保证redis性能。
			AOF持久化，每次执行记录到单独的日志文件，重启redis会从文件中恢复数据，两种方式都开启时，redis优先用aof恢复。‘
			两者优缺点：
				AOF文件比RDB更新频率高，优先使用AOF还原
				AOF比RDB更安全更大
				RDB性能比AOF好
				都配了优先加载AOF

	redis扩容
		redis被当作缓存，可以使用一致性hash实现动态扩容缩容

	redis过期键的删除策略
		三种： 1、定时过期(每个key创建一个定时器，过期立即清除，对内存友好，但会占用大量CPU资源，影响吞吐量)。 2、惰性过期(有key访问的时候，再去判断是否过期，过期就删除，节约cpu，对内存不友好)。 3、定期过期（每隔一定时间就扫描数据库中的key，并清除过期的key）。 redis使用惰性过期和定期过期两种结合使用

	redis保证都是热点数据
		redis数据集上升到一定大小时，会施行数据淘汰策略

	redis的淘汰策略
		全局键空间选择性删除
			01: noeviction: 内存不足，新写入报错。   02: allkeys-lru: 内存不足，移除最少使用key(最常用)。  03: allkeys-random: 内存不足，随机移除key
		设置过期时间的键空间选择性移除
			01: volatile-lru: 内存不足，在设置过期时间的键中，移除最少使用key.    02: volatile-random: 内存不足，在设置的过期键中，随机移除key
			03: volatile-ttl: 内存不足，在过期键中，更早过期时间key移除。

	redis线程模型
		基于reactor模式开发的网络事件处理器，这种被称为文件事件处理器。由4个部分组成：多个套接字，IO多路复用程序、文件事件分派器、事件处理器。文件事件分派器队列是单线程的，所以redis才说是单线程的。
			事件处理器使用IO多路复用监听多个套接字，并根据套接字当前执行的任务关联不同的事件处理器。当监听的套接字执行连接应答、读取、写入等操作时，对应的事件就会产生，然后进行处理。
			所以运用这些实现了高性能的网络通信模型，又很好的对redis中其他单线程模块进行对接。

	redis事务：
		redis通过multi、exec、watch等一组命令的结合完成事务，一个事务中所有命令都会被序列化。
		redis事务的三个字段：事务开始multi、命令入队、事务执行exec.
		redis事务主要通过multi、exec、discard、watch四个原语实现
		redis不支持回滚，如果一个事务命令出现错误，所有命令都不会执行。如果事务出现运行错误，正确的命令能执行。

	redis哨兵：
		作用：集群监控，消息通知，故障转移，配置中心
		哨兵核心： 至少需要3个实例，保证健壮性。不保证数据零丢失，能保证redis高可用性。

	redis集群：
		工作原理：
			01: 通过哈希方式，将数据分片，每个节点均分存储一定的哈希槽的数据，默认分配16384
			02: 每份数据分片存储多个互为主从的节点上
			03: 数据写入主节点，在同步到从节点
			04: 同一分片多个节点间的数据不保持一致性
			05: 读取数据时，当客户端操作key没分配到该节点，redis返回转向指令，转向正确的节点。
			06：扩容时需要把旧节点数据迁移到新节点。
			07: 节点之间通信协议用gossip协议。
		优点：
			01: 无中心架构，支持动态扩容，业务透明。   02: 具备sentinel监控和自动故障转移能力。  03: 客户端连接集群中任何一个可用节点即可。  04: 高性能，高可用
		缺点：
			01: 运维复杂，数据迁移需人工干预
			02: 只能使用0号数据库。   03：不支持批量操作。  04: 分布式逻辑和存储模块耦合	

		分布式寻址算法：
			01: 一致性hash算法 + 虚拟节点
		哈希槽：
			集群引入哈希槽，集群有16384个哈希槽，每个key通过CRC16校验后对16384取模，每个节点负责一部分哈希槽。



rocketMQ相关面试题：

	rocketMQ消费模式有几种？
		由consumer决定，维度是topic。分为集群消费和广播消费。
		集群消费就是一条消息只会被同group的一个comsumer消费，多个group,就是不同group下买安的consumer。
		广播消费：对group下各个consumer都消费一边。

	rocketmq消息是push还是pull
		没有真正意义上的push，都是pull，有push类，单底层采用长轮询机制	

	为什么要主动拉取消息而不使用时间监听方式
		事件驱动方式是建立好长连接，由事件的方式来实时推送。
		如果broker主动推送消息的话，可能会出现push速度快，消费速度慢的情况，会造成消息consumer端堆积过多。且不能被其他consumer消费。pull的方式可以当前自身情况来pull，不会因为过多的压力造成瓶颈，采用pull的方式。

	broker如何处理拉取请求？
		consumer请求broker中有符合条件的消息
		有：01(响应consumer) 02(等待下次consumer的请求)
		没有：01(defaultMessageStore#ReputMessageService#run方法)
		  02(PullRequestHoldService来Hold连接，5s执行一次检查pullRequestTable有没有消息，有就立即推送)。
		  03(每隔1ms检查commitLog有无新消息，有就写入pullRequestTable).
		  04(有新消息时返回请求) 
		  05(挂起consumer的请求，不断开链接，不反悔数据)。
		  06(使用consumer的offset)

	rocketMq如何做负载均衡
		通过topic在多broker中分布式存储实现。
		producer端：执行message queue发送消息到对应broker,来达到写入的负载均衡
			01:提升写入吞吐量，当多个producer同时写入一个broker时，性能会下降。 02: 消息分布在多broker中，为负载消费做准备
			默认的策略：producer维护一个index。  每次取节点自增。  index向所有broker个数取余   自带容错策略
		consumer端：采用平均分配算法进行负载均衡	

	rocketmq如何保证重复消费
		引起重复消费的原因：ACK、消费模式、网络的不确定性
		解决方案： 数据库、Map、 redis

	rocketmq如何保证顺序消费：
		多个queue保证单个queue里的顺序，本身queue天然就是顺序的，过个queue无法绝对保证消息的有序性。所以可以强调顺序消费的话，同一个topic,同一个queue。
		如何保证发送到同一个queue, rocketmq提供给我们一个messageQueueSelector接口，重写接口，实现自己的分配queue的算法。

	保证消息不丢失？
		上面有，我就不说了，1、生产者同步发送和异步发送。 2、刷盘机制。3、broker的高可用。4、消费者的消息确认以及重试机制。5、事务消息。 6、极端情况，集群挂了，生产者降级，消息发送存在数据库中，等集群恢复后，在根据存储信息消费或发送

	rocketmq在分布式事务原理
		half message：预处理消息，broker收到此类消息，存储RMQ_SYS_TRANS_HALF_TOPIC消费队列中。
		检查事务状态：开启一个定时任务，消费上面topic的消息，执行任务向消息发送事务执行状态，如果是未知，定时回调重新检查
		超时：超过回查次数，默认回滚。


Dubbo面试题：
	dubbo核心功能有哪些？
		remoting: 网络通信框架，提供多种Nio框架抽象，包括同步转异步和“请求响应”模式信息交换方式。
		cluster: 服务框架，提供基于接口方法的透明远程过程调用，包括多协议支持，软负载均衡。
		registry: 服务注册，基于注册中心目录服务，消费方能动态查找服务提供方，地址透明。

	dubbo核心组件
		Provider：暴露服务的服务提供方	
		Consumer：调用远程服务消费方
		Registry：服务注册与发现注册中心
		Monitor：监控中心和访问调用统计
		Container：服务运行容器	

	dubbo服务注册发现流程
		1、服务容器Container负责启动，加载，运行服务提供者。
		2、服务提供者Provider在启动时，向注册中心注册自己提供的服务。
		3、服务消费者Consumer在启动时，向注册中心订阅自己所需的服务。
		4、注册中心Registry返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
		5、服务消费者Consumer，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。
		6、服务消费者Consumer和提供者Provider，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心Monitor。

	dubbo为什么选用zk
		树形的目录服务，支持变更推送。数据模型简单，有一系列称为znode数据节点组成，数据存储在内存中，支持集群，高可用。


zookeeper面试题：

	zookeeper是什么？
		一个开源的分布式协调服务。集群的管理者。能实现到发布/订阅， 集群管理，分布式锁等功能。它里面保证了分布式一致性：
			1: 顺序一致性。 2：原子性。3、单一视图。 4、可靠性。  5: 实时性（最终一致性）	
			读请求可以被任意一台机器获取，如果读请求注册监听器，监听器也由对应zk机器处理。写的话因为会同步所有集群，所以机器多的情况会导致写的吞吐量下降。
			有序性是非常重要的特性，所有更新是全局有序，每个更新都会有对应的时间戳zxid,每次读请求会带有zxid

	zookeeper提供什么？
		文件系统、通知机制
		文件系统：zk里面维护的是像那种树状的目录结构，并且他每个节点，就是znode都是可以存储数据的，目录也可以存数据，最大1m。

	ZAB协议？
		支持恢复崩溃的	原子广播协议，比如启动挂了，进入崩溃恢复模式，重新选举leader节点，然后进行数据同步通信。完成数据同步后，恢复到广播模式，leader开始处理客户端的请求。

	四种类型节点：
		临时节点（生命周期跟客户端绑定）、持久节点（除非手动删除，否则一直存储）、临时顺序节点(节点名后边会追加一个由父节点维护的自增整型数字)、持久顺序节点

	wathcer机制（数据变更通知）：
		客户端注册watcher,  服务端处理watcher, 客户端注册watcher			

	服务器角色：
		leader、 follower、 observer(处理客户端非事务请求)

	zk的四种状态；
		looking: 寻找leader模式
		following: 跟随者状态。
		leading： 领导者状态
		observer: 观察者状态

	数据同步：
		流程均以消息传递的方式进行
			01: learner向learder注册  
			02: 数据同步： 四种方式（1、直接差异化同步。 2、回滚在差异化同步。 3、仅回滚同步。  4、全量同步）
			03: 同步确认


项目中解决问题方案：
	1、为什么要搞分库分表
		01: 产生性能瓶颈，IO瓶颈和CPU瓶颈，这种会导致数据库活跃连接数增加。
			IO瓶颈：读IO瓶颈，热点数据太多，导致数据库缓存放不下，产生大量的磁盘IO，查询速度慢。可以采用一主多从，读写分离的方案，用多个从库分摊查询流量。或者采用分库+水平分表的方案。
				写IO瓶颈，写入频繁，产生频繁写入IO操作，导致大量的活跃连接。导致无连接可用的后果，可采用分库方案，用多个库分摊写入压力。
			cpu瓶颈：sql问题，包含join，group by, order by，非索引字段增加cpu运算操作，会对cpu产生压力。可以考虑sql优化
				单表数据量太大，遍历树的层次太深或者扫描行太多，sql效率低。根据业务场景水平分表

	2、分库分表方案
		01: 利用mycat、kingShard这种代理中间件分裤分表。好处是和业务代码耦合度很低，只需做一些配置，接入成本低。缺点是需要单独部署，从低哦啊用链路上多了一层，分库分表逻辑完全由代理中间件管理，对程序员完全是黑盒，本身出问题后，无法查询和存储相关业务数据。
		02: 利用sharding-jdbc,TSharding等jar包形式轻量级组件分库分表，缺点是有一定的代码开发工作量，对业务有侵入性。好处就是对程序员透明，逻辑把控会更强。
		03: 使用云平台的分布式数据库服务

	3、sharding如何实现分库分表
		如果对于日增量1000万左右，可以分16个库，每个库16张表，五年内数据库压力基本可控。
		01: 可以用供应商编号进行hash,找到对应库和表，这里16是2的N次幂，所以取模和hash值按16位运算一样，效率高于取模运算。如果直接查数据库，可能还会出现性能问题，我们上层加一个缓存层，使用redis,redis做分片集群，存储热点供应商的热点商品数据，如果商品数据太多，可以按照热度存近50或者100条这种。能减少到一部分数据库查询压力。数据库走主从，每个分库有两个从库，查询走从库，分摊分库压力。
		02: 上述方案有缺陷，如hash取模产生数据倾斜的问题，扩容缩容非常麻烦，可以使用一致性hash方案解决，基于虚拟节点设计原理的一致性hash可以让数据分布更均匀。而且采用环形设计思路，增减节点时，使数据迁移成本更低。扩容时要成倍扩容，在hash还上每个节点间隙增加新的节点，这样才能分摊原有节点访问和存储压力。
		03: 解决数据倾斜问题：
			数据倾斜出现时，需要考虑二次分表，添加一定数量的表，然后按照对应规则将对应数据迁移至新表。可利用一致性hash算法对倾斜的数据表进行二次分表。
		04: 一致性hash介绍
			就是环形的一个思路，根据hash值将所有节点映射到hash环上，顺时针查找。实际使用的话，服务器节点有限，也有可能数据不均匀的情况，存在大量数据映射到某一个节点的情况，运用虚拟节点，其实就是实际节点在hash环上的复制品，一个实际节点可以对应到多个虚拟节点，虚拟节点越多，数据分布就越均匀。

	4、针对数据散落，需要聚合查询的情况
		不同供应商数据散落，如果有天要查多个供应商的信息，就需要从所有数据库数据，聚合在一起，代码实现比较复杂，性能也相对较差。可以采用es + HBase组合的方案，将对应索引值加入到es中，可以实现到多条件检索能力。
		
		
	5、项目中用到的数据模型
		



 
		



			
	





	

				







	












