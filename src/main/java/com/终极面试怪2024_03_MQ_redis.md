#MQ开始了哦
###先讲RocketMQ
1、**`RocketMQ事务消息如何实现？`**
    rocketMQ的事务消息通过TransactionListener接口实现。
    整个流程：01、先给Broker发送一条half半消息，half消息存储在broker端中，此时不会发送给消费者（标记为prepared状态）。 02、half消息发送给消息发送方（也就是生产者）
        03、生产收到half消息后提交本地事务，并发送commit或者rollback消息。 04、rocketMQ接收到反馈后，rollback就回滚该事物，提交就将消息还原成原始消息，传给消费者。
        04、消费者消费消息（如果消费失败，则会重试，直到最终一致性）
    问题点：01：如果生产者收到half消息后，broker一直收不到commit或者rollback怎么办？
        答：如果在规定时间内没收到，rocketMQ会向应用程序发送一条检查请求，看回调方法是否能收到该事务消息，如果应用程序还是在规定时间未响应，标记为unknow状态。标记unknow状态的消息，
            如果应用程序有结果，还可以向MQ发送commit或者rollback。但如果超过72小时，mq会自动回滚该事务消息。
        02：第一次发送half消息失败怎么办？答：重试
        03：为什么要用事务消息？答：本地事务执行完成后发送消息可能会发送失败，消费者无法处理，导致数据不一致。有了这个可以保证数据一致性。

2、**`RocketMQ如何保证消息顺序性？`**
    01：概念：它只支持在同一个队列内消息能做到有序性，不同queue中的消息是无序的。如果想要发送顺序消息，在send方法中，传入MessageQueueSelector。（在里面需要实现select方法，然后指定到那个messageQueue）。
    02：如何保证消费者有序消费：发送到同一队列后，消费者通过有序消费模式MessageListenerOrderly实现，这个实现里面通过三把锁保证顺序消费，
            第一把锁（确保消息只会投递到同一消费者）：保证同一个队列的有序消息可以被顺序消费，broker就只会把消息发到同一个消费者上，这时就需要加第一把锁，在consumeMessageOrderlyService初始化时，启动一个定时任务，
                尝试向broker为当前消费者客户端申请分布式锁。获取成功后后续消息就只发给这个消费者。
            第二把锁（对messageQueue加锁，确保只有一个线程处理这个消息队列）：消息拉取时，消费者会一次性拉取多条消息，放入ProcessQueue，然后提交到消费线程池。为保证顺序消费，所以一个队列只能
                一个线程处理队列消息。
            第三把锁（processQueue加锁确保重平衡过程中不会出现重复消费）：获取到第二把锁后，就可以从processQueue依次拉取一批消息处理，为保证消息不重复消费，需要对processQueue加锁。
    03：为什么需要第三把锁？ 答：为了重平衡，如果新增消费者，发生重平衡，比如队列原来属于客户端A消费，现在重新分配给客户端B去消费，可能存在一部分数据重复消费，所以对processQueue加锁。
    04：顺序消费存在的问题：这三把锁的方式可能会降低系统吞吐量，而且出现消息阻塞的话，可能会达到系统瓶颈。

3、**`RocketMQ如何保证消息不丢失？`**
    想要确保不丢失，需要生产者、broker、消费者的共同协作，缺一不可
    01、首先在生产者端，消息的发送分为**同步发和异步发**，同步发会阻塞等待Broker返回结果，如果这个时候出现异常，发送失败，则进行重试。异步发送需要生产者重写sendCallback中的方法，
        用于broker端回调，在方法中确认消息是成功投递还是需要进行重试。
    02、在broker端，在接收消息后刷盘的操作分为**同步刷盘和异步刷盘**，默认是异步，他会先将消息存储到内存中，也就是page cache中，这个时候就会将确认结果发给生产者，
        如果这时出现page cache还未刷到磁盘就宕机的情况，消息就会丢失。这种可以设置为同步刷盘，直到刷盘成功才确认消息。
    03、broker部署的时候保证高可用也可提高消息可靠性，这时rocketMQ可以采用集群的方式部署，可采用**一主多从**的部署方式，并利用主从同步的方式进行数据复制。当主节点宕机时，
        也可从从节点获取消息。异步复制问题点：默认使用异步复制的方式，如果写入master成功后，然后master确认响应给消费者，这个消息会复制到从节点，但是此时master宕机或
            磁盘损坏，这样会导致消息丢失。
           所以解决这个问题，可以配置同步复制的方式，即master同步给从节点在返回给生产者确认消息。
    04、消费者端 确保消息拉取并消费成功后给Broker返回ACK，如果broker没收到消息，则进行重试。这样来保证消息不丢失
         （在业务逻辑处理完后最后一步返回return consumeConcurrentlyStatus.CONSUME_SUCCESS）
    

4、**`RocketMQ实现延时消息？`**
    rocketMq支持延迟消息，message.setDelayTimeLevel(3)意思设置延迟级别3，就是延迟10S。5.0之前只支持1s到2h中间的几个时长，并且使用Timer定时器来实现延迟投递。
    5.0之后新增了基于时间轮实现的定时消息。它是一种高效的定时器算法，能处理大量的定时任务，并在O(1)时间内找到下一个执行的任务，因此提高消息投递性。

5、**`RocketMQ消息堆积怎么办？`**
    01、产生原因：消息堆积一般是因为客户端本地消费过程中，由于消耗耗时过长或消费并发度小等原因，导致消费能力不足，出现消息堆积。
    02、问题排查（可不答）：实践：消息订阅不一致（应用因特殊原因，将springCloudStream改为rocketMQ，修改配置上线后，出现消息堆积问题，经排查是两个东西一个配置了一个MQConsumerInner）
            导致rocketMQ不确定是否消费，就先堆积到broker中。
    03、如何解决：1、增加消费者数量，让更多消费实例消费这些消息。2、提升消费者消费速度：如果时消费慢的情况，可以考虑引入线程池、放入缓存或本地消息存储后直接返回成功，然后异步处理。
            3、降低生产者生产速度：如果生产可控的时候可以考虑 4、清理过期消息：过期消息，无法成功的消息，经过评估后，进行删除。 
            5、调整MQ配置参数：如消息消费模式、消息拉取间隔时间等 来优化消费效率。 6、增加topic队列数：如果一个topic的messageQueue比较少，可增加队列的方式提高消息处理并发度。
    
6、**`rocketMQ怎么实现消息分发？`**
    01、支持两种消费模式：广播模式、集群模式
        广播模式：当为此模式，每条消息都会推送给集群内的消费者，保证消息至少被消费一次。但是它并不会重投消费失败的消息，并且每一次重启都会从最新消息开始消费。
        集群模式：mq认为任意一条消息只需要集群内任意消费者处理即可，集群模式下只会被分发到一台机器上处理。
        
5、**`rocketMQ消息是推还是拉？`**
    分为两种，一种是推push，一种是拉pull（push是服务端主动推送给客户端，pull是客户端主动轮询拉取服务端数据）
    push优点是及时性好，但客户端没做好流控，服务端推送大量消息到客户端，就会导致客户端消息堆积或崩溃。
    pull优点就是一句自己消费能力进行消费，频繁拉取会给服务端造成压力，也存在消费不及时问题。
    01、pull在rocketMQ建议使用DefaultLitePullConsumer，并且提供subscribe和assign两种模式。需要注意的是，rocketMQ的push模式其实底层实现是基于pull实现的。
        里面是基于http长轮询实现的。push主要实现是在pullMessageProcessor的processRequest，在里面会创建一个轮询任务，逻辑在pullRequestHoldService的子线程。
        这个现场每隔一段时间（5秒或20秒），执行一次数据拉取（具体实现在checkColdDataPullRequest方法）

6、**`rocketMQ一定能实现削峰的效果嘛？`**
    削峰填谷就是高并发场景下，面对大量请求，用mq缓冲这些请求，将大量并发暂存到队列中，然后按照系统能处理的速度逐渐消费，避免系统崩溃。
    但是用了mq就能实现削峰填谷嘛？答：不一定，要看MQ的消费方式，有推和拉的两种模式，如果是推push模式，如果上游发送消息后，会立即推给消费者，如果数据量太大，
        客户端承担很大请求量，如果消费能力不满足，就会出现消息堆积，最终系统崩溃。所以，在削峰填谷时，推荐使用pull模式，自己控制消费速度，这样消息就是堆在broker上。

7、**`RocketMq高可用性？`**
  	通过broker主从机制实现高可用
  	消息生产的高可用：在创建topic时，把topic的多个message queue创建在多个broker组上，当一个broker组的master不可用时，生产者可以给其他broker上面继续发消息
  	消费消息的高可用：不能支持配置从master读还是slave读，当master不可用或者繁忙的时候，会自动切换到slave中读，保障了消息消费的高可用
  	消息存储结构： commitLog（存储消息的元数据）、ConsumerQueue（存储消息在CommitLog的索引）、indexFile(提供一种通过key或者时间区间查询消息的方法)
  	刷盘机制：同步刷盘、异步刷盘（可能会造成消息丢失）
  	主从复制：同步复制、异步复制（异步复制）
  	producer负载均衡： producer在发送消息时，默认轮询所有queue,消息发送到不同的queue上，queue分布在不同的broker上。
  	consumer负载均衡：默认的分配算法AllocateMessageQueueAveragely（每个consumer实例平均分配每个consume queue）
  	消息重试：
  		发送端重试
  		消费端重试：对于顺序消息，进行消息重试的时候，后续消息会被阻塞。这一块监控要做好，避免后续消息阻塞
  	重试队列和死信队列：
  		消息失败进入重试队列
  		失败后达到最大重试次数后，进入死信队列，以DLQ消费组命名	


###redis搞一搞
1、**`redis的集群模式？`**
    主要三种模式：01、主从复制（最简单的集群模式，主节点负责处理所有写操作和读操作，而从节点则复制主节点的数据，进行读操作，如主节点故障，需手动将从升为主）
        02、哨兵模式 （为解决主从无法自动容错及回复问题，增加哨兵节点，这些节点会定期发送ping，指定时间没收到pong，就主观下线，被多数节点标记主观下线后，
                    升级为客观下线，然后触发故障转移）
        03、cluster模式（分布式集群方案，它将数据自动分片到多个节点，每个节点复制部分数据。cluster能自动检测节点故障，然后推举从升主，
                    它适用于大规模应用解决方案，提供更好的横向扩容和容错能力）
        （数据分片是在redisCluster中，使用哈希槽的方式进行数据分片，整体分为16384个槽，然后根据CRC16算法得到一个结果，对16384取模找到对应槽点）
            数据分片的优点：01、提升整体性能和吞吐量 02、提高可扩展性 03、更好的资源利用 04、避免单点故障 05、数据冗余和高可用性
            为什么设置16384个槽？：01、心跳数据包携带节点的配置信息，在更新配置时，如果包含16384个槽，使用2k空间即可，如果是65535，就要8k   
                            02、cluster集群不太可能超过1000个主节点，所以65535对应slot太多，数据迁移时成本高。

2、**`redis和memcached有什么区别？`**
    01、数据结构不同 02、持久方式不同（mem没有持久化）03、数据分片方式不同（redis使用哈希槽，mem只能手动）
    04、处理数据方式不同（redis单线程，mem多线程） 05、协议不同 06、内存管理方式不同
    总结：redis适用于数据结构复杂，更高级和数据持久化的场景，mem只适合简单键值存储场景。

3、**`redis为什么这么快？`**
    1、基础答案：01、基于内存。 02、单线程模型（不需要线程切换或上下文切换） 03、多路复用I/O模型（采用I/O多路复用技术，单个线程也能处理多个客户端连接能力）
            04、高效的数据结构（底层实现都非常高效，能在O(1)时间复杂度完成） 05、多线程的引入（redis6.0中，使用多线程来处理网络）
    2、进阶问题点：**单线程也能这么快**？？
        这里就是IO多路复用的功劳，redis底层其实对IO多路复用是基于linux的多路复用技术，linux中多个进程IO可注册到同一管道，这个管道同一与内核交互，管道内
            某一请求准备好之后，就把数据拷贝到用户空间。
        然后redis包装了IO多路复用的函数库，比如select、poll，epoll都对应单独的文件。所以redis中，每个套接字的操作都是产生一个文件事件，然后由文件事件分派器
        给到每个事件处理器。
    3、进阶问题点：**为什么设计成单线程**？？
        这个单线程，指的是网络IO和键值对由一个线程完成，其他的如持久化存储模块，集群支持模块等都是多线程。

4、**`redis的数据类型？`**
    01、字符串(字符串，自定义sds) 02、列表(list，) 03、哈希(hash)  04、集和（set） 05、有序集和（zset）
    还有其他高级类型：bitMap、geo、hyperLogLog

5、**`字符串中为什么定义SDS？`**
    首先redis中字符串应用非常广泛，所以至少要求：01、支持任意字符存储 02、各种操作需要高效
    C操作字符串有几处问题：01、它字符串表示结束是在最后一个字符中加\0表示结束（这种实现不能保存任意字符内容）。
        02、对于一些基础操作，字符串长度，字符串追加，需要从头遍历（效率有点低）。
    所以redis为解决问题，定义了sds，在字符串中增加一个alloc字段（表示分配给该字符数组的总长度），一个记录现有长度的len字段。不依赖\0为结尾。

6、**`redis中zset是怎么实现？`**
    zset底层数据结构由listPack和跳表组成(3.0之前用的压缩列表)，在具体实现中不仅用到跳表，还有字典。应用场景：做一些排行榜，分数，排序场景。
    跳表用来实现有序集合，按照分值大小排序，它的插入、删除查找复杂度都是O(logn),key用dict字典存储，时间复杂度为O（1）。
    跳表的实现：
        它是在链表的基础上改造的，实现一种呢多层的有序链表，所以查找的过程中在多个层级上跳来跳去，最后定位元素，当查询复杂时，他的时间复杂度O(logn)
        从高层级往低层级查对应数据，节点层数设置最理想的比例是2：1，因为这样复杂度可以降到O(logn),redis是创建节点时，随机生产节点层数（先产生0-1的随机数，
            然后低于0.25就创建一层，最高限制64，因为这样就相当于楼层增高概率时25%，层越高，概率越低）。

7、**`为什么lua脚本可以保证原子性？`**
    并发编程中的原子性指的是操作不可拆分，不被中断。lua脚本保证原子性是因为redis会将lua封装成一个单独的事务，由redis服务器自行处理并完成整个事务。
       如果这个进程有其他客户端请求时，redis会暂存起来，直到lua脚本执行完成，才会恢复请求。redis保证了redis的原子方式执行lua脚本，但是不保证所有操作执行或回滚。
    lua脚本优点：1、高效性 2、简单性 3、可移植性 4、灵活性 5、安全性

8、**`redis持久化机制是怎么样的？`**
    提供两种持久化机制：RDB和AOF。RDB定期保存到磁盘，AOF就是追加写操作。
       RDB优缺点：优点（01、快照文件小 02、恢复速度快 03、适合做备份和灾难恢复）。缺点（定期更新可能会丢数据）
        
        

        
        
    
    
        
