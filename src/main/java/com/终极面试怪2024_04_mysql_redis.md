#数据库和redis开始了哦
###先讲mysql
1、**`innoDB和myISAM区别？`**
    01、innoDB支持事务，myISAM不支持。 02、InnoDB是聚集索引，myIASM是非聚集索引。 03、InnoDB支持外键，my不支持。 
    04、InnoDB最小粒度是行锁，my最小粒度是表锁 05、innoDB在5.6之前不支持fulltext类型索引 06、inno不保存行数，my会保存 
    07、自增长字段，inno必须包含只有该字段索引，my可以建联合索引。 08、删除表inno是一行一行删，my是直接重建表。

2、**`char和varchar区别？`**
    char是定长数据类型，长度固定并且在存储时会自动在结尾添加空格来将字符串填满指定长度。
    varchar是一种可变的数据类型，只存储实际的字符串内容，不填充空格，存储短字符串时，可节省空间。
    优缺点：varchar优点：可变长的字符串类型，具有收缩性，兼容性更好。
           varchar缺点：01、因为可变，在缩短和扩张时，因为mysql之间是连续存放在文件地址中，可能会造成也分裂和页合并的问题。02、还可能产生内存碎片
                03、varchar额外存储了1到2个字节的长度信息。
        char优点：定长字符串，减少内存碎片，无需额外磁盘空间存储长度信息。 char缺点：会丢失列末尾的空格信息。设计不规范时，造成空间浪费。

3、**`mysql5.X和8.0的区别？`**
    01、性能（8.0速度比5/7快2倍，从读/写工作负载，IO密集型工作负载等）02、隐藏索引（8.0后，索引可以被隐藏和现实。隐藏时不会被优化器使用，可以利用这个特性来走性能调试）
    03、取消查询缓存（为了提高查询性能）04、select for update支持no wait（加了nowait后，如果发现竞争关系，会抛错）

4、**`为什么不建议使用多表join？`**
    不建议使用，是因为join效率低，mysql是使用了嵌套循环的方式实现关联查询的，简单说就是两层循环，一张做外循环，一张内循环。
    具体实现的算法是simple nested loop（两两对比，复杂度N*M），block nested loop(引入一个Buffer，基于内存查)， 
            index nested loop（有索引的话，用索引，复杂度N*logM）。这三种效率都不是特别高。
    如何解决：01、查出来后，在代码中自己处理相应关系后，二次查询，在内存中关联。 02、数据冗余，将重要数据冗余，避免关联 
            03、宽表：基于join关系，做一张大宽表，同步到ES

5、**`一条查询sql的执行过程？`**
    分下面几个步骤：1、使用**连接器**,与mysql建立连接，并校验权限。 2、8.0之前会检查是否开启查询缓存，如果sql相同，就返回缓存给客户端。
        3、由**解析器**进行语法分析和语义分析，并生成解析树，然后由**预处理器**检查解析数的合法性。 4、然后**优化器**生成执行计划，看是否优化sql。
        5、**执行器**执行sql语句，然后返回结果，开始查询缓存则缓存。

6、**`mysql中行格式？`**
    01、compact是5.0前的默认格式，除字段值外还记录变长字段长度列表和头信息（null值列表）。02、redundant（很少用）
    03、dynamic：5.7后引入，compact升级版，结构大致相同。 04：compressed（5.1的新特性，可以对存储数据压缩，减少磁盘占用空间）

7、**`一条更新sql的执行过程？`**
    一次更新操作，设计到bufferPool、binlog、undoLog、redoLog以及物理磁盘，完成的操作如下:
    01、在buffer pool中读取数据：更新前先查buffer pool是否有该记录。没有就从磁盘读取改页到buffer pool中。
    02、记录undoLog：用undoLog记录修改前数据。UndoLog是用来保证事务原子性和一致性的一种机制，通常用于事务发生回滚，将值回滚到修改前的状态。
            它最开始写到内存中，然后由一个后台线程定时刷新到磁盘中。
    03、在buffer pool中更新：执行update语句时，先更新bufferPool数据，不直接写入磁盘。然后将修改的这个数据页设置为脏页。
    04、记录redoLog buffer：在bufferPool修改的同时，会把修改操作写入redoLog buffer中。
    05、提交事务：提交时，将redoLog写入磁盘，保证事务的持久性。
    06、写入磁盘：提价后，先把bufferPool的脏页写入磁盘，保证数据的持久性。写入先是写到pageCache中，然后后台线程异步写入磁盘，可能会存在延迟。
    07、记录binlog：提交时，也会将事务信息记录到binlog中。binlog是用来实现主从复制的机制，里面记录信息比较全（包括事务开始时间，数据库名，表名，事务ID等）
    （注意：binglog和redolog，都是通过2阶段提交保证一致性）

8、**`什么是脏读、不可重复读、幻读？事务隔离级别？为什么默认为RR？`**
    1、01、脏读：读到其他事务还没提交的数据。02、不可重复读：对某数据进行读取时，其他事务修改了数据，导致第二次读的时候数据不一致。
        03、幻读：事务做范围查询时，另一个事务插入或删除数据，导致范围查询结果条数不一致。
        所以，mysql定义了4中隔离级别来解决这些异常情况：读未提交、读已提交、可重复读、顺序执行。
    2、事务隔离级别：
        01：读未提交：最低的隔离级别，这种级别下，可以读到其他事务的数据，存在幻读、脏读、不可重复度的问题。
        02：读已提交：事务修改后，如果没提交，另外一个事务不能读取。防止了脏读发生。
        03：可重复性读：解决了不可重复读问题，同一事务中修改后数据跟修改前数据一致。但无法彻底解决幻读。
        04：可串行化：所有问题都能解决。性能极差。
    3、**为什么mysql默认使用RR隔离级别**
        01、首先mysql主从同步时，从服务是通过主服务器的binLog进行的，binLog主要支持三种格式：statement，row以及mixed。当为statement时，记录的是sql原文。
        02、如果我们使用read commit，两个事务，A事务删除数据，B事务新增数据，B事务比A事务先执行，由于是RC隔离级别，即使A事务删除在B事务后，B事务插入操作不会看到
        A事务的删除操作。所以会保留B事务的插入数据。
        03、这个时候binLog记录就会两条记录，因为B事务比A事务先执行，所以binLog记录的是插入操作，然后在删除操作。
        04、那么binLog同步到从节点时，它回放binlog时，就是先插后删，数据没了。
        05、为了避免这个问题发生，mysql默认使用RR级别，因为在RR级别中，更新数据时会加行级锁，还会增加GAP锁。
    4、**为什么默认RR，大厂要改成RC**
        答：虽然RR的隔离级别在一定程度上避免脏读、不可重复读和幻读问题，但是大厂都更愿意换成RC级别，从而提高并发度并降低死锁的概率。
        RR和RC的区别：01：一致性读（快照读）：RR和RC读取的时候都会使用一致性读，RC还支持半一致读
        02：锁机制：mysql中的三种类型锁（记录锁，间隙锁，next-key锁），在RC中，只对索引增加记录锁，不会加间隙锁或其他。RR中为了解决幻读问题，会加间隙锁。
        主从同步：如果改为RC，那么binlog的格式一定不能时statement，可以选择row或者mixed。
        所以：大厂选择RC就是为了提高并发，减少死锁。对不可重复读和幻读利用其他手段保证，比如乐观锁，或者在代码层面。

9、**`InnoDB如何解决脏读、不可重复读和幻读？`**
    在innodb中，通过MVCC解决脏读和不可重复读，通过MVCC+间隙锁解决幻读。
    脏读的解决：在RC及以上读取时，innoDB获取最新的全局事务ID，这个ID表示当前时刻所有已提交事务的最新状态。确保事务只能看到在它开始之前已经提交的数据版本。
    不可重复度读的解决：通过MVCC来解决不可重复读的问题，在RR级别中，就在第一次读取的时候生产一个read view，后续所有快照读都使用同一个read view。
    幻读的解决：基于MVCC+间隙锁，某种程度上可以避免幻读的发生，但没办法避免。

10、**`innodb的RR到底有没有解决幻读？`**
    在RR中，大部分场景都能解决幻读情况，因为加入了MVCC+间隙锁，避免新的数据插入或更新，所以对于快照读的幻读问题，能解决幻读（因为快照读读取后会生成一个读取快照）。
    **不能解决的幻读情况**：在两个事务中出现快照读和当前读，比如：01（两个事务，事务1先进行快照读，事务2插入一条记录并提交，然后事务1update数据， 
            update会触发当前读，会读取最新数据，就会产生幻读）。02（还是两个事务，1先进行快照读，2还是插入并提交，1进行当前读（select..for update）也会发生幻读）
    如何避免幻读：01、RR级别中，能使用快照读就是用快照读。 02、并发场景中，一定要加锁的话，在事务一开始就立即加锁，也能有效避免。

11、**`什么他妈的是MVCC，如何实现？`**
    多版本并发控制，他其实跟数据库锁一样，都是并发控制的手段。在读写并发时，通过MVCC来解决不可重复读问题。
    MVCC的机制，最重要的一个概念就是快照读,它是实现MVCC的基础。这个快照读是怎么形成的？
        1、这个快照读是从undoLog里面取的快照，undoLog是用于回退的日志，事务没提交前，会记录更新前的数据到undolog里面。所以快照读就是从undolog里面取的更新前的数据。
        2、并且存储的行记录中有三个隐式字段，db_row_id(隐藏主键)，db_trx_id(最新修改的事务ID)，db_roll_ptr(回滚指针，指向上个版本的快照地址)，可以组成快照链。
        3、然后根据read view能得到具体读取哪个快照，read view就是来解决可见性的问题，里面有几个重要属性：trx_ids（未提交的事务ID列表），low_limit_id(分配给下一个事务的id)
            up_limit_id（事务中最小的事务id），creator_trx_id（创建readview的事务id）。
        4、那些快照能看到，或不能看到？那就是事务ID大的事务应该能看到事务ID小的事务。

12、**`innodb的锁机制？`**
    01、什么是排他锁和共享锁：innodb的锁在级别上划分：一个是共享锁（S锁），一个是排他锁（X锁）。
            共享锁又称为读锁，读读共享，只能读不能写（select...lock in share mode）。排他锁又称为写锁，加锁之后其他事务不能加锁啦（select...for update）.
    02、什么是意向锁：除了X锁和S锁之外，还有意向锁。
            意向锁是为了解决不同锁粒度之间的并发性问题（一种锁协议）。当一个事务请求获取一个行级锁或表级锁时，会自动获取意向锁。有两种类型：意向共享锁和意向排他锁。
    03、行锁锁的是什么？：
            行锁根据粒度不同，分为三种。01、recordLock（记录锁）锁的是索引记录。02、gap lock（间隙锁），锁的是索引记录之间的间隙。
                03、next-key锁（记录锁和间隙锁的组合）同时锁索引记录和间隙，左开右闭。
    总结锁的分类：01、按照锁粒度（全局锁，表级锁，行级锁） 02、锁的级别（共享锁、排他锁） 03、锁的使用方式（乐观锁、悲观锁） 04、锁的对象（记录锁，间隙锁，next-key 锁）
                其他锁分类：意向锁、插入意向锁、auto-incr锁

13、 **`innodb加索引，这个时候会锁表嘛？`**           
    5.6之前，索引构建期间会进行表锁，其他回话不能读取或修改表中任何数据。这会存在长时间阻塞和性能问题。
    5.6后引入online DDl技术，允许不阻塞的其他回话的情况下创建或删除索引。
    online DDL是尽最大可能保证DDL期间不阻塞DML动作。其内置算法是copy和nplace（可指定），copy就是用一张临时表然后进行rename操作。
        nplace使用原地算法进行ddl操作，不重新创建和复制。

14、**`innoDB索引类型，为什么用B+树？`**
    mysql的常见的索引数据结构分为：hash索引，B+树索引，其中b+树索引最常见，最有效。
    01、B+树索引：又分为聚集索引（由主键构建的B+树），和非聚集索引（叶子节点不包含记录，只包含索引值和主键的值），根据索引唯一性，又分为唯一索引和普通索引。
    02：innoDB为什么用B+树实现：
        首先看B+树的特点（1、一个平衡树 2、关键字放在叶子节点上 3、顺序存放 4、非叶子结点不存储实际数据，只存索引 5、叶子节点通过双向链表）
        用B+树的优点：01、支持范围查询 02、支持排序 03、存储更多的索引数据 03、节点分裂或合并时，IO操作少。 04、有利于磁盘预读 05、有利缓存
        缺点：维护成本相对较高（因存在页分裂和页合并）
    03：与hash索引区别：01、B+树索引列按照大小排序存储，适合范围查找和排序操作，hash索引更适合等值查询。 02、B+树维护成本相对较高。
        03：B+树在磁盘上是有序存储的，hash是无序的，区间查询时效率低。

15、**`索引回表，什么是索引覆盖，怎么设计索引？`**
    当我们使用非聚簇索引时，会先查到非聚簇索引对应的主键值，然后在通过主键的值查询数据，这种叫回表。
        所以：主键查询是效率最高的，另外可以利用覆盖索引、索引下推等技术，减少回表次数。
    02、什么是索引覆盖、索引下推？
        覆盖索引指一个查询语句的执行只用从索引取得即可。比如mysql只通过索引返回自己想要的列数据，无需回表。索引下推就是5.6引入的优化技术。
    03、设计索引的时候有哪些原则（怎么设计）？
        01、考虑查询的频率和效率 02、选择适合的索引类型 03、考虑区分度（比如状态枚举，数据倾斜比较严重的字段） 
        04、考虑联合索引（经常使用多个列查询的） 05、考虑覆盖索引（减少回表次数）06、避免创建过多索引（创建过多索引会占用大量磁盘空间，写入性能降低）
        07、合适的索引长度（索引建议不要太长，索引列长度越长，索引效率越低） 08、执行计划分析（执行explain，经常观察索引是否被使用）
            
16、 **`索引一定会遵循最左前缀匹配原则吗？`**   
    索引底层是B+树，在构造B+树时，它会按照左边的key进行排序，左边key相同才会按照右边key排序。所以mysql一定是遵循最左匹配原则，8.0之前是正确的，8.0后不一定，
        因为8.0引入了索引跳跃扫描。索引跳跃优化其实就是最做索引区分度不高的情况，比如最左的索引（性别）这种字段，真正要不要走索引条约扫描，需要经过mysql优化器成本预估的。
        所以：尽量不要依赖这种优化。
        
17、**`uuid和自增id做主键哪个好？`**
    uuid优缺点：优点（01、全局唯一 02、不可预测性 03、分布式） 缺点：（01、存储空间比较大 02、不适合范围查询 03、查询效率低 04、无业务意义）
    自增ID优缺点：优点（01、存储空间小 02、查询效率高 03、方便展示 04、分页方便（可用id解决深度分页））缺点：（01、分库分表 02、可预测带来安全性问题 03、可能用尽）
    
18、**`order by的实现？`**
    order by是用来做排序的，具体怎么排序取决于优化器选择，如果优化器认为走索引快，就会用索引排序。否则就会使用filesort，能走索引排序的情况并不多，很多时候还是走的fileSort。
    fileSort这种排序方式，如果排序内容少，就基于内存中sort_buffer排，否则就使用临时文件排。实际情况中，字段长度不长的化，可能会使用全字段排序的方式直接
        在sort_buffer中返回结果集，如果字段长的化，就采用row_id排序，就需要二次回表了。
    01、索引排序：索引排序是效率最高的，排序的过程中是否走索引，完全取决于优化器。我们在优化sql过程中可以注意以下几种情况更容易走索引排序：
            （1、查询的字段和order by的字段组成了一个联合索引，并且符合最左匹配原则。 2、查询条件有limit，并且数量不高 3、where条件中通过常量查询）
    02、fileSort：上面提到用fileSort时，mysql会分配一个sort_buffer用于排序，大小由配置项sort_buffer_size控制。
            如何排序数据量小于size，就走内存，否则就用磁盘临时文件排序（临时文件排序相对内存排，会慢很多）。
    03、全字段排序和row_id排序：除了上述所说的size，还有一个参数max_length_for_sort_data，默认1024字节，如果单行长度超过这个值，就会采用rowId排序，
        否则用全字段排序。全字段排序就是将所有字段放到sort_buffer中，然后根据排序字段排，全字段排序好处：就是只用回表一次。缺点：字段如果太多，耗费sort_buffer
         空间，就会使用临时文件排序。 
        未了避免全字段排序字段太多，用rowid排序：其实就是不用将全字段放进去，只把排序字段和主键放进去。相比全字段排序：多了一次回表。

19、**`count(1)、count(*)、count(列名)区别？`**
    count(1)和count(*)表示直接查询符合条件的数据库表行数，而count(列名)表示查询符合条件的列的值不为null的行数。
    性能方面，1和*根本没区别，除了*是sql的标准统计行数的语法。count(*)的优化：在innodb下，mysql除了聚集索引外，还有非聚集索引，聚集索引存的是所有的值，
        非聚集索引存的是索引+主键，相比下比聚集索引小很多。所以mysql在count(*)时优先选择最小的非聚集索引扫表。
    count(列名)上来就是直接全表扫，还需判断字段是不是null，性能就有点拉胯胯。

20、**`mysql深度分页问题？`**
    mysql limit m,n的原理就是先读取前面的m+n条记录，，抛弃前M条，返回n条数据，所以m越大，偏移量越大，性能就越差。尽管limit做了一些优化
        （01、limit几行的情况，可能会使用索引。 02、limit和Order by一起使用时，会找到排序结果对应的count行数据后就停止排序，并不是对整个结果集排序）
    如何解决深度分页问题：
        01、使用子查询和join优化 02、使用子查询和id过滤优化（弊端就是需要id自增）03、使用搜索引擎（如es）
    
21、**`binlog、redolog、undolog区别？`**
    都是日志文件类型，但各自的作用和实现方式有所不同。
    01、区别：binlog主要用来做数据库备份、崩溃恢复和数据复制等操作。redo log和undo log主要用于事务管理，记录的是数据修改操作和回滚操作，
            redolog用来做恢复，undolog用来做回滚。
    02、binlog是用于记录数据库所有的ddl和dml的一种二进制文件，记录了所有数据库操作，格式分为基于语句的格式和基于行的格式。
    03、redolog是mysql用于实现数据恢复和数据持久化的一种机制，把事务的操作搞到redo log，当数据丢失时，可以用redolog恢复数据。
    04、undolog就是做事务回滚或系统崩溃时回滚事务的操作。另外，undolog还支持到MVCC机制，对并发事务执行提供一定的隔离性。

22、**`用了索引还是慢，是什么原因？`**
    01、选错索引：一个sql走多个索引时，优化器会选择一个，但这个选择可能选错，选错索引可能会比较慢。
    02、数据分布不均匀: 如果某些索引上的数据量有点大，而另外的节点上数据量少，可能会慢。
    03、sql语句存在问题：比如多表join、select *很多字段。
    04、数据库设计不合理：设计结构不合理，导致大量扫表。
    05、硬件或网络波动

23、**`sql执行计划分析时，需关注的哪些信息？`**
    explain计划中，共有12个字段。重点关注加粗的4个字段。
    01、id（每个操作的唯一标识）02、select_type(操作的类型) 03、table(操作的表) 04、partitions(涉及的区) 
    05、**type**(查询所用的索引类型，包括ALL,index,range,ref,eq_ref,const)等 06、**possible_keys(可能被查询优化器选择使用的索引)**
    07、**key（查询优化器选择的索引）** 08、**extra（额外的信息，包括using index， using filesort，usingtemporary）**
    如果判断一条sql有没有走索引？
        首先看key有无值，有值就是走了索引树，具体怎么用，要看type和extra。type中all全表扫，index（表示全索引扫描，会遍历整个索引树，一般是不遵循最左原则）
        range（范围扫描）ref以上就算是性能比较好的。 再看extra中描述的是执行查询时做的附加操作：using where(检索数据后，在进行条件过滤，非索引或非覆盖索引)
        using index（表示mysql使用了覆盖索引，无需回表） 到时候面的时候介绍两个即可。

24、**`如何优化一个大规模的数据库系统？`**
    1、硬件优化：（提高内存、磁盘、cpu、网络带宽） 2、数据库设计：（表结构优化，数据归档） 3、查询优化（sql优化、查询计划分析）
    4、索引优化（合适的索引，避免过多索引，使用覆盖索引等）5、缓存机制（查询缓存，对象缓存）6、负载均衡（读写分离，数据库机器）
    7、分区和分片（分库分表）8、数据备份和恢复 9、性能监控和调优
    
25、**`怎么造成死锁？如何解决？`**
    mysql锁的是索引，不是记录。如果我们在一个事务中更新，用普通索引作为条件，会先获取普通索引的锁，然后在尝试获取主键索引的锁。
        这个时候另外一个线程，先获取主键索引的锁。这个时候就会死锁。
    造成死锁原因：1、资源竞争 2、未释放资源 3、不同事务的执行速度不同 4、操作数据量过大
    如何解决死锁：
        01、大部分数据库管理系统会自动干预，通常是回滚其中一个或多个事务打破死锁。02、可以用管理工具手动强制回滚。
        03、mysql中的死锁检测，通过配置项可设置等待超时时间。
    如何避免死锁：01、减少锁数量 02、减少锁的时长 03、数据顺序访问 04、减少操作数据量

26、**`索引失效怎么排查？`**
    使用explain执行计划分析，重点关注key,type,extra字段。如果发现走了索引但是慢，这种就看上面的22题。
    然后看用了索引但是没走索引是为什么？
        01、索引参与计算 02、索引列进行函数操作 03、使用OR（只有两边都是=判断，并且都有索引才会走索引），
        04、like操作 05、隐式类型转换 06、!=、is not null、in如果使用不恰当，也会索引失效
    
    

    
    
    