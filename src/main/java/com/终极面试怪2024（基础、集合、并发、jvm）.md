`java基础`：

1、**`java中基本类型为什么还需要包装类`**
    在使用集和类中，我们无法将int、double等基本类型放入集和中，因为要求的是object类型，所以为了让基本类型也有对象的特征，并为其添加属性和方法，丰富操作。他们两区别在于01：默认值
不同，02：初始方式不同 03：存储方式不同，基本类型存储在栈上，包装类型存储在堆上。包装类还有自动拆箱和装箱功能，其实就是通过包装类中valueOf()方法实现。integer包装类将-128 ~ 127缓存起来

2、**`为什么不能用浮点数表示金额`**
    因为不是所有小数都能用二进制表示，比如0.1,0.1的二进制会出现无限循环的情况，所以IEEE规范剔除了一种使用近似值表示小数的方式，引入了精度的概念，这就是浮点数。0.1+0.2 != 0.3

3、**`为什么不能用bigDecimal的equals方法做等值比较`**
    bigDecimal里面有两个属性，value和标度（scale），在使用equals时，不仅会比较值，还会比较精度scale，对于0.1和0.10，值一样，精度不一样，使用equals就返回false。推荐使用compareTo，
bigDecimal(double)中，因为double自身表示的是一个近似值，所以创建出来的值比如new BigDecimal(0.1)并不是0.1

4、**`BigDecimal中的应用，如何实现的精确计数`**
    里面有一个无标度值（intVal，实际值）和标度（scale，表示小数点后的位数），一个数值为123.45，无标度值就是12345，scale就为2。123.45 = 12345 * 10^(-2)，标度为负数时，往左移对应位数

5、**`java中的负数取绝对值一定是正数嘛`？**
    Math.abs(intVal), 假如intval传入的是-2145483648=-2^31，取绝对值后应该是2145483648，但是这个超出了int的最大范围，俗称越界，这个时候值math.abd(-2145483648) = -1。并且
发生越界问题时不会报错的，所以开发时需注意。

6、**`string、stringBuilder、stringBuffer的区别`**
    string是不可变的，stringBuilder和stringBuffer是可变的，Buffer是线程安全的，而builder是非线程安全的。string为什么设置为不可变性，主要是从缓存、安全性、线程安全和性能角度出发。
缓存：字符串使用时最为广泛的，所以大量字符串是非常耗资源，java提供了一个字符串池，增加其缓存功能，节省空间。安全性：字符串还经常用于存储账号密码登敏感信息，所以字符串的内容是不可变的，
就可以相信这个字符串。并string是线程安全的，线程访问时都为同一个。builder和Buffer里面也是数组char[],不过不是final修饰的，并且这个数组长度不是所有位置都已经被使用，因为append中会扩容。
Buffer就是每个方法加上synchronized。不要再for循环中使用 **+** 拼接字符串，因为它是语法糖，在反编译后其实是new stringBuilder().append(str);

7、**`string是如何保证不可变性`**
    1、string类被声明为final，不能被继承，里面方法无法被覆盖 2、用final修饰字符串内容char[],一旦被初始化，就不能指向其他数组 3、string类没有提供用于修改字符串的公共方法，如果是修改
只会创建一个新的string对象。string的长度限制分为编译期和运行期，编译期间用constant_utf8_info表示字符串常量的值，限制是65535，运行期间length参数是int类型，所以最大长度是2 ^ 31 - 1。
jdk9中把string的char[]改为了byte[],这是因为java内部使用utf-16每个char占据两个字节，即使某些字符用一个字节表示，仍会占用两个字节。所以引入了compact string概念，源码中还有个coder，0表示
Latin1编码格式，1表示utf-16格式。

8、**`string str = new string("hollis")创建了几个对象？`**
    创建对象数应该是1个或者2个，首先在new的过程中，都会在堆上创建一个对象，至于另外一个对象，就看具体情况。另外一个对象就是常量池中的字符串常量，如果是第一次执行，同时会创建两个对象，一个是
字符串常量引用的对象，另一个是我们new出来的，如果不是第一次执行，就会创建我们new出来的。

9、**`什么是SPI，与api有啥区别`**
    API直接被应用开发人员使用，SPI被框架扩展人员使用，APi用于定义调用接口，而SPI用于定义和提供可插拔的实现方式。spi的应用场景：调用这根据实际使用需要，启用、扩展或者替换框架的实现策略。
比如01：数据库驱动加载接口实现类的加载 02：jdbc加载不同类型数据库的驱动 03：日志门面接口实现类加载

10、**`反射机制是什么，为什么反射慢`**
    反射机制指的是运行时能够获取自身信息。java的反射可以判断一个对象所属的类、成员变量、方法、调用方法等。反射的好处就是可以提升程序的灵活性和扩展性。但是缺点就是：01：代码可读性及可维护性
变低，02：反射代码执行的性能低 03：反射破坏了封装性。之所以慢是因为：01：涉及动态解析的类型，不能执行jvm优化，如jit优化 02：反射使用时参数需要从object[]拆包，过程中可能会产生很多对象，容易
gc。 03：反射调用时会编码从方法数组中查找，检查可见性，都是耗时的 04：使用反射参数时有额外检查

11、**`如何破坏单例模式`**
    使用反射或使用反序列化都可以破坏单例模式，反射中setAccessible(true)后，使得反射对象使用时取消java语言访问检查，私有的构造函数能被访问。反序列化中会通过unsafe直接分配内存的方式
创建一个新对象。如何避免破坏单例模式：反射方式破坏时，在构造函数加判断，singleton！=null的情况，反序列化破坏时，定义readResolve方法，返回当前对象，因为反序列判断时，会有一个判断，
如果实现了serializable方法，包含readResolve方法时，直接返回true。

12、**`java的动态代理如何实现`**
    jdk动态代理：reflect包中的proxy类和InvocationHandler接口提供了生成动态代理类的能力。cglib动态代理：cglib是一个三方类库，运行时动态生成子类对象从而实现目标功能的扩展。jdk动态代理
的对象必须实现一个或多个接口，不然使用cglib实现。主要应用在各个框架，如aop、过滤器、拦截器等

13、**`fastjson的反序列化漏洞`**
    在最前版本时，如果一个类包含接口或抽象类，在进行序列化时会抹去子类型，导致反序列时拿不到原始类型。后续引入了autoType，就是序列化时记录原始类型，结果黑客利用这个特性，假如@type反序列化
相关对象，对相关类实现攻击。

14、**`什么是AIO、BIO、NIO`**
    BIO:同步阻塞IO，线程发起io请求时，一直阻塞，知道缓冲区就绪。AIO：同步非阻塞IO，线程发起io请求，不需要阻塞，用户线程不需要原地等待，先做其他操作，只需定时轮询检查io缓冲区是否就绪。
AIO:异步非阻塞IO模型，发起io请求，不阻塞，也不定时轮询，异步io回调通知。

15、**`java是值传递还是引用传递`**
    值传递和引用传递最大的区别是传递过程中有没有复制一个副本来传递，如果是副本，就是值传递，否则就是引用传递，java对象传递，是通过复制的方式把引用关系传递了，因为有复制的过程，所以是值传递。只不过
传递的内容是对象的应用。

16、**`深拷贝和浅拷贝`**
    浅拷贝指将一个对象复制到另外一个变量中，只复制对象的地址，而不是对象本身，原始对象和复制对象实际上共享同一个内存地址。java中beanUtils基本是浅拷贝。好处就是性能好，没有复杂对象时考虑用浅拷贝。
深拷贝指将一个对象及其所有子对象复制到另一个变量中，创建一个全新对象。不共享，修改后不受影响，深拷贝需要实现cloneable接口，重写clone方法。还是使用序列化的方式实现深拷贝，比如fastjson，或者实现
Serializable接口后使用SerializationUtils.clone

17、**`Arrays.sort采用什么排序方式`**
    根据参数类型的不同，提供了不同的排序方式，对于int、double、char等数据排序，使用双轴快速排序，而对对象数组的排序方式，使用归并排序和timSort

18、**`final、finally、finalize区别`**
    final用于声明、方法或类，使之不可变、不可重写或不可继承。finally：用异常处理的一部分，用于确保代码块执行总是执行。finalize：object的一个方法
用于对象被垃圾回收前执行清理操作，不推荐使用。

19、**有了equals为啥需要hashcode方法**
    equals和hashcode通常都是成对的，equals用于判断两个对象是否相等，hashCode是生成对象的哈希码，确定在哈希标的位置。equals比较两对象是相等的，他们的hashcode必须返回相同值。对于要有
hashcode，一方面是效率，快速计算在哈希表的位置，一方面是保证数据的一致性和准确性。

20、**`stream并行流一定比串行流快嘛`？**
    不一定，stream底层使用forkJoin并行处理，当并行处理的时候,线程管理的开销、任务分割、线程争用、数据依赖性、环境配置。一般单核cpu下，串行比并行效率还高，多核cpu下，如果元素数量比较少，
串行也比并行好。

`集和类冲冲`

21、**`Java集和类有哪些`**
    分为五类：list、set、queue、stack、map，继承关系来讲，前三种是collection的子接口，表示可循环。功能上讲：list是一个容器，可以先进先出，也可先进后出。set是无序的，同时不重复，他会根据
equals、compareTo、hashCode比较，list分为有链表和数据实现，链表增删快、数组查询快。queue分为优先队列、双端队列等。map分为hashMap和排序的treeMap。

24、**`arrayList、linkedList、vector区别`**
    都实现了list接口，功能相似。arrayList是一个可改变大小的数组，大小可动态增加，本质上就是一个数组。linkedList是一个双向链表，添加和删除时有更好的性能，get和set方面稍弱。vector强同步
里面是线程安全的，这也导致其性能问题，arrayList初始化容量为10，比较小，可以预估数量的前提下建议分配一个初始化值，减少扩容的开销。vector扩容是两倍扩，arrayList是1.5倍

25、**`arrayList序列化是怎么实现的`**
    arrayList底层通过object数据完成，被声明了transient,在默认的序列化策略中并没有序列化数组字段。为了避免Java自带序列化机制造成空间浪费，所以把数组定义了transient，并且重写writeObject
和readObject来实现序列化操作

26、**`hash冲突怎么解决`**
    常见五种方案：01：开放定址法（一旦发生冲突，就去寻找下一个空的散列地址，直到找到空的将记录存下，常见的有线性探测、二次探测、双重散列，缺点就是聚集问题，降低性能）02：链地址法（最常用解决hash冲突，
每个bucket 指向一个链表，冲突时加到链表末尾，Java8就是用这个解决hash冲突，超过阈值后转红黑树）03：在哈希法，冲突时再次计算另一个hash函数，知道冲突不发生为止，需要额外的计算。04：建立公共溢出
区（建立溢出表，冲突的数据放进去））05：一致性hash（将数据均匀分布到多个节点减少冲突，常用于分布式系统，如果redis集群）

27：**`能讲讲hashmap嘛？`**
    首先，hashmap是基于数组加链表的方式实现的，通过计算hashCode的方式找到对应数组下标，如果发生hash冲突，就放到链表中，且超出阈值后转为红黑树。它并不是线程安全的，并且key可以允许为null，默认
的初始容为16，超过75%后进行扩容，扩大至原先两倍，然后重新分配。   其中获取元素是get方法：他会经过hash后计算数组的位置，然后查找对应数组或链表是否有对应值。插入元素使用的是put方法：先计算hash值，找到索引
位置，如果为空，插入，不为空，跟键值对比较，相等就替换，不相等就插入到链表中或红黑树中，成功返回成功，失败返回null，成功后如果需要扩容，进行一次扩容操作。

28、**`hashMap如何定位hash位置的？`**
    首先计算hash函数时使用(key.hashCode ^ (key.hashCode >> 16))，这里是个扰动函数，高16位和低16位进行异或操作，得到扰动后的hashCode，这样做是让hash尽可能分散一点。然后再put时
在通过(table.length - 1) & (扰动函数后的hashcode)得到对应的位置，这里相当于 (扰动函数后的hashcode) % 2^n,只不过二进制比10进制运算快。并且如果key为null，做了一个特殊处理，
总是放在数组的第一个元素中。

29、**`hashMap如何保证长度2的n次方？为什么默认负载因子为0.75？`**
    长度为2的n次方是为了保证取模运算的时候进行位运算，因为直接用%取模要转成10进制，为了提高效率直接 & 上2^n-1，前提是2的n次方。所以在初始化和扩容的时候，默认16，如果初始化了对应长度，它会自动计算为
2的n次方。负载因子设置为0.75，刚好为3/4,然后临界值计算方式为 临界值=负载因子 * 容量（默认16），这个是经过计算的，如果太大会导致大量的hash冲突，太小又会浪费空间，0.75怎么乘都能保证是整数。在阿里开发
手册里面建议设置初始化大小，这个大小最好是 (初始大小 / 0.75 + 1)

30、**`hashMap如何扩容的？为什么要转红黑树？`**
    当put的时候判断size+1后判断>临界值，大于就扩容，分三个部分01：如果桶节点没有链表，直接rehash到其他桶。02：如果桶有链表，重新链接后统一移动，不用一个个节点rehash。03：链表形成红黑树，
元素小于6时，取消树化操作。 之所以选择红黑树，就是因为在bucket冲突多时，链表会变得比较长，复杂度为o(n)。 所以需要一个东西替代链表，二叉树就是比较好的选择，不过
二叉树最坏情况可能会退化成链表，二叉平衡树因为要严格保证高度差，所以插入和修改时较为耗时。红黑树在自平衡的同时，插入最多两次旋转，删除最多三次。基于综合情况，选择红黑树

31、**`concurrentHashMap是如何保证线程安全|`**
    jdk7使用分段锁的技术，及默认分了16个段，每个段独立的锁，这样多个线程同时访问时，只需要锁住相关段即可（但是在高并发的情况下，仍然出现锁竞争，导致性能下降）。
jdk8使用节点锁思想，采用cas+synchronized，如果某个段为空，就使用cas操作添加新节点，不为空则使用synchronized锁住当前段，再次尝试put。这样可以避免锁力度太大，
以及过多锁竞争问题。
  对于jdk8废弃分段锁，主要是在并发高的情况下，会导致热点段，从而成为性能瓶颈。jdk8相对于7来讲有以下特点：01：更细的锁粒度。02：cas操作（无锁操作）03：性能和扩展性（减少锁竞争）
04：内存效率（通过减少锁的数量，提高内存效率）

32、**`concurrentHashMap在哪些地方做了并发控制`**
    jdk8是在初始化桶数极端和设置桶、插入链表、树化等阶段，都会有并发问题。初始化桶阶段，做了自旋操作和cas操作，没有线程就初始化，有就让出cpu时间片。put阶段发现桶没值就采用
cas插入，有值就按照桶节点加锁，然后将值插入链表或红黑树。

33、**`如何将集合变线程安全`**
    01：使用synchronized或reentrantLock加锁 02：使用threadLocal 03：使用collections.synchronizedXXX()方法。04：使用不可变集合，入ImmutableList。

34、**`HashMap在并发场景有什么问题`**
    1.7在扩容时，会将元素插入链表头部，即头插法。所以在多线程下可能会产生死循环的问题，导致cpu100%。1.8采用尾插法解决此问题。除死循环外，都会在以下出问题。
01：多线程put时，size个数不一样 02：put时，上个值覆盖 03：get时，因为另外一个线程扩容换了桶，导致get不到数据

35、**`COW是什么，如何保证线程安全`**
    copy-on-write，是一种优化思路。最基本思路，最开始的时候大家都共享同一个数据内存，如果有人想改动数据，就把内容copy出去一个新的内容然后再改，就是延时懒惰策略。
就是一种读写分离的思想，并且cow适合用于读多写少的并发场景，如白名单，黑名单，商品类目的访问。不过注意，add、set、remove方法时开销很大，因为要复制整个数组

36、**`ConcurrntHashMap为什么不允许为null值？`**
    hashMap可以允许key、value为null，而在concurrentHashMap中，key、value不允许，主要是因为非并发的map是可以容忍二义性，在并发map中时无法容忍的。因为hashmap是为
单线程设计的，他get数据的时候，数据为null，可以用contains方法检测是否key、value包含null。而在并发场景中，拿到null值后，是没法通过contains方法准确检测是否包含null值。
所以为了让concurrentHashMap语义更加准确，所以不能存在二义性的问题。

37、**`ConcurrntHashMap在加锁时为什么使用synchronized而不是reentrantLock`**
    8相对7来讲是对节点加锁，锁的粒度小，并发冲突小的多，所以用synchronized不会频繁升级为重量级锁，大部分偏向锁和轻量级锁就搞定，性能这块于lock就相差不大。并且sync还有几个优势：
01：synchronized无需手动锁管理，不会有忘记锁释放的风险 02：它时jvm内置语义，jvm运行时会进行优化措施，如锁粗化，消除等 03：锁获取失败时，先是通过自旋操作的，lock是线程挂起，
会有线程上下文切换的问题。


###开始并发操作了哦

38、**`什么是多线程上下文切换，什么时候会发生上下文切换？`**
    cpu上下文切换是指多个线程共享时间片，一个线程在cpu时间片执行完后，需要切换到另外一个线程执行。这个时候需要保存当前线程的状态信息，如程序计数器，栈针，寄存器信息等。上下文切换开销比较大的，
因为在多线程中需要保存和恢复上下文信息，过多的切换会降低系统循行效率。如何减少上下文切换呢？01：减少线程数，通过合理的线程池减少线程创建和销毁。02：使用无锁并发编程 03：使用cas算法。
  04：合理使用锁，减少同步块执行时间，从而减少线程等待时间。  
    什么时候会发生切换呢？01：任务正常结束，cpu正常调度下一个任务。02：i/o阻塞，挂起，cpu切换在一个任务 03：抢占锁资源，当前任务未抢到，挂起，切换。04：当前任务挂起，如sleep，就会切换。
    05：硬件中断

39、**`线程有几种状态，状态流转是怎么样？`**
    Java线程状态分为6种：01：初始（NEW，新建一个线程，未调用start）02：运行（runnable，将就绪状态和运行状态统称运行）03：阻塞（blocked，表示阻塞于锁）04：等待（waiting，需要等待其他线程做出特定操作）
05：超时等待（timed_waiting，出wait外，可以指定时间自行返回）06：终止（terminated）
    Java在调用wait方法后进入waiting状态，而timed_waiting是执行sleep方法时进入。这两种状态都会让出cpu。但不一样的是wait方法后会释放锁，sleep不会释放对象上的锁。Java锁的目标是对象，所以wait、
notify、notifyAll针对的也是对象，所以定义在object中，sleep不需要释放锁，所以在thread类中。
    线程为什么运行状态是就绪和运行时一起合并出来的，主要是单cpu情况下，所有线程是串行执行的，为了能让线程看起来是并行，所以需要分成时间片执行。让看起来是并行执行一样。所以在一秒钟内，可能一部分时间处于
ready状态，另一部分时间处于running状态。

40、**`创建线程有几种方式`**
    四种方式，01：继承thread类创建线程 02：实现runnable接口 03：通过callable和futureTask创建 04：通过线程池。 其实归根到底就两种，就是继承thread和实现runnable

41、**`什么是线程池，如何实现、生命周期？`**
    线程池是池化技术的典型代表，提前创建一批线程，保存到线程池中，当任务需要执行时，从池中选一个执行。所有创建出来的线程池都实现了executorService接口，常用方法有以下：
    01：newFixedThreadPool(创建固定目标线程池，超出目标的放入队列中，队列长度无限) 02：newCachedThreadPool(可缓存的线程池，缓存一段时间后过期，但是会无限创建线程) 
    03：newSingleThreadExecutor(创建单线程化的executor) 04：newScheduledThreadPool(创建一个支持定时及周期性的任务执行线程池)
如何实现：首先它的构造函数中就有对应的数据结构，01:acc(获取调用上下文) 02：corePoolSize(核心线程数量) 03：maximumPoolSize(最大线程数量) 04：workQueue(多余任务等待队列)
05：keepAliveTime(非核心线程空闲时间)，06：threadFactory(创建线程的工厂) 07:handler(线程拒绝策略)
其次就是开始execute时添加一个任务：判断线程数小于corePoolSize，小于就addWorker，否则判断线程池是否运行，运行则看是否允许插入，插入成功后再次验证，如果没运行，溢出，然后执行拒绝策略，如果
在运行，没有线程了，就启用一个线程。核心代码在addWorker中，总共分为五步：01(判断是否能添加工作线程条件过滤，线程池状态大于或等于shutDown状态，不处理提交任务) 02(做自旋，更新创建线程数量，如果
当前线程数小于corePoolSize，则开始创建新线程) 03：（获取线程池住锁，通过reentrantLock锁保证安全） 04：（添加线程到workers中） 05（启动新建的线程）。
workers底层数据结构是hashSet
    线程池的生命周期包括：running、shutdown（不接收新任务，但是处理队列中任务）、stop（队列也不处理了）、tidying（所有任务处理完成，线程数0）、terminated（执行完毕）
    
41-1：线程池的拒绝策略
    Java提供4中策略：01：abortPolicy-默认的拒绝策略，也是最常用的，当超过了最大队列后就直接拒绝新任务。02：discardPolicy：队列满了，新任务提交后会默默被丢弃，没任何提示
  03：discardOldestPolicy：也会丢弃任务，队列满了，删除最早的任务。04：callerRunsPolicy：队列满了，将新任务退回给调用线程，不抛出异常。

42、**`threadLocal能讲讲嘛`**
    threadLocal是多线程解决并发的一个途径，通过为每一个线程创建一份共享变量的副本来保证各个线程间访问和修改互不影响。他里面有一个threadLocalMap的数据结构，存储对应的key和value，这个map的entry
继承了weakReference弱引用，使用不当的情况下会导致oom。在我们系统中，threadLocal的应用场景一般使用在：01(用户身份存储) 02(traceId存储，追踪日志) 03(线程安全，比如simpleDateFormat实例)。
threadLocal为什么会引用weakReference，是因为localMap中key是thread对象，这个对象有两个引用源，一个是栈上的threadLocal引用，另一个是map中entry对它的应用。如果栈上的引用随着方法结束后断开，
但是entry还存在他的引用，所以一直无法被回收，导致oom。所以引入了弱引用，如果发生gc的时候可以被直接回收，减少oom情况。key的oom解决了，value的引用是强引用，所以需要手动remove掉。

43、**`线程同步的方式有哪些？`**
    synchronized、reentrantLock、semaphore、countDownLatch、cyclicBarrier

44、**`什么是死锁，如何解决？`**
    死锁是指两个或以上的线程或进程在执行过程中，竞争资源永远相互等待。产生死锁的必要条件：01：互斥条件（一个资源只能一个进程使用）02：占有且等待（阻塞时，对资源保持不放）03：不可强行占有（未使用完不可占有）
04：循环等待条件（头尾相接导致死循环等待）
    如何解决：01：破坏不可抢占（设置优先级）02：破坏循环等待（最常用的，比如数据库事务，A事务A->B->C，B事务C->D->A，这样会死锁，如果事务B顺序改为A->D->C就行）

45、**`Java内存模型`**
    JMM是一种为了解决多线程下通过共享内存通信时，导致本地内存数据不一致、编译器对代码指令重排序、处理器对代码乱序执行等问题。它就是一组规范，
 内存模型解决并发主要采用两种方式，限制处理器优化和使用内存屏障。随着cpu不断升级，cpu的主存和本地内存之间有高速缓存，这种在多线程下就会出现缓存一致性问题。
所以jmm底层封装了volatile、synchronized、final、concurrent包等解决内存数据不一致、指令重排、顺序性的问题。
比如Java为了保证原子性，使用两个高级的字节码monitorEnter和monitorExit，这个来保证原子性。使用synchronized和volatile保证多线程的有序性。

46、**`激动人心的synchronized请讲讲实现`**
    synchronized主要用来加锁，有以下几个特点：01(互斥性，同一时间点只有一个线程获取锁) 02(阻塞性，未获得锁的线程只能阻塞，等待锁释放) 03（可重入性，锁未释放，再次请求锁，可以获得锁）
作用于方法和代码块，锁的内容就是对象，无论是同步方法还是代码，都依赖对象的监视器（monitor，监视锁）。synchronized有几个关键属性：01(_entryList:存放等待锁block状态的队列)
02(_owner:指向持有锁的对象) 03(_waitSet:存放wait状态的线程队列) 04(_count:获取该线程获取锁的次数)。
当多个线程访问同步代码块时，首先进入_entrySet队列中，当某个线程获取monitor后进入_owner区域，并且_count+1。当monitor的线程获得wait方法后，_owner变为空，count-1，
然后进入_waitSet集合中等待唤醒。当前线程执行完毕后释放锁，让后面线程获取。
在加锁的过程中会调用对象拥有的objectMonitor的enter方法，解锁调用exit方法。jdk6之前，这种调用enter和exit方法被称为重量级锁，因为线程的阻塞和唤醒都需要操作系统帮忙，
从用户态转为内核态，这种状态转换花费时间较多。所以jdk6后面进行了优化，出现轻量级锁、偏向锁、锁消除、锁粗化等操作。

47、**`synchronized如何保证原子性、可见性、有序性`**
    首先原子性是因为cpu时间片的问题导致的，synchronized通过monitorEnter和monitorExit字节指令，到进入enter后获得锁，只能有当前线程访问，锁未释放前没有其他线程能访问到
即使发生了cpu时间片切换，下一次过来还是这个线程获得，直到代码执行完后释放锁。02：对于有序性的保证：
synchronized其实没有保证处理器优化的乱序问题以及指令重排问题，只不过有序性的概念是（在本线程观察，所有操作是天然有序的，但是在另一个线程角度观察，操作是无序的），所以
synchronized就是保证了同一时间只有一个线程访问，这样就能保证有序性。03：对于可见性的保证：synchronized强制要求如果修改了一个变量时，在解锁之前，要把此变量同步到主存中，
让其他线程可见。

48、**`synchronized锁升级过程`**
    jdk6之前只有重量级锁，1.6加入偏向锁、轻量级锁、重量级锁。Java中由锁标志位markWord表示。'01'表示无锁和偏向锁状态，'02'表示轻量级锁状态，'10'表示重量级锁。对于锁升级：
偏向锁的情况：当 synchronized首次进入时，锁对象进入偏向模式，此时记录线程ID到对象头，此时如果由其他线程访问，判断线程ID，相同继续获取锁，不同就升级为轻量级锁。  
轻量级锁的情况：升级时就是尝试获取轻量级锁，首先jvm将对象头中mark word复制到线程栈中锁记录，然后尝试通过cas操作更新对象头的markWord，如果更新成功，获取轻量级锁成功，失败则升级重量级锁。
重量级锁的情况，轻量级锁cas更新失败后，说明有线程进行实际的竞争了，这个时候先把对象头中记录指向waitSet中，表示进入等待队列进行竞争了。

49、**`synchronized锁升级过程中几次自旋`**
    升级过程中有两次的自旋，第一次是偏向锁升级轻量级锁时，在获取轻量级锁的时候进行cas，这里发生第一次自旋，尝试从获取其他线程持有的轻量级锁，这里在自旋等待，最多自旋15次。
第二次是在轻量级升级到重量级过程中，就是当线程尝试获取其他线程的重量级锁时，会自旋等待，不过jdk8中默认未开启。在自旋的过程中，还引入了自适应自旋，可以根据轻量级锁自旋等待的情况，
动态调整。

50、**`synchronized锁优化`**
    jdk6引入了自旋锁、锁消除、锁粗化等优化操作来优化锁操作。为什么引入自旋锁：在线程处理时间较短的情况下，自旋等待比从等待区唤醒线程效率要高，他们两的区别就是要不要放弃cpu
的处理时间，自旋锁不放弃cpu，时刻检查共享资源是否可以被访问，阻塞锁是放弃cpu，进入等待区被唤醒。如果锁竞争不激烈的情况下，推荐使用自旋锁。
    锁消除：其实就是JIT编译器借助一种被成为逃逸分析技术来判断同步块所使用的锁对象是否只是被一个线程访问，而不用被其他线程锁访问到，比如局部变量加锁。  
    锁粗化：JIT编译器发现代码中在for循环中对同一对象加了 synchronized锁，这时候会把加锁操作放到循环体外，防止重复加锁。
    
51、**`volatile能保证原子性嘛？它是如何保证有序性，可见性的`**
    第一个，volatile不能保证原子性，因为它不是锁，只能保证有序性和可见性。关于它如何保障可见性的：被volatile修饰的变量进行修改写操作时，jvm会向处理器发送lock前缀指令，
将这个变量写到主存中，让其他线程可见。volatile禁止了指令重排的优化，能够保证代码执行的顺序性，主要时通过内存屏障来实现的。
    为什么有了synchronized还需要volatile，因为synchronized说白了还是一种锁，锁就有几个缺点：01：性能损耗 02：产生阻塞。volatile相对来讲不使用锁，并且还有一个附加功能，
就是禁止指令重排，在单例模式下的双重校验锁中，如果不佳volatile，可能会发生指令重排的情况，会抛出NPE。
    这里顺便说在内存屏障：为了保证volatile变量的可见性和禁止指令重排序，Java会生成字节码中插入内存屏障实现。内存屏障就是一种cpu指令，防止cpu或编译器重排序。

52、**`如何理解AQS`**
    AQS(抽象队列同步器)是很多同步器的框架，如reentrantLock、countDownLatch、semaphore等都是基于AQS，除此之外，我们还可以定制锁需要的同步器。
AQS内部维护了一个FIFO队列（CLH队列）以及volatile的int类型变量state，当state为1的时候，表示对象锁被占有，state变量值由cas操作来修改。CLH队列用来实现多线程排队工作，
当线程加锁失败，该线程被封装成一个Node节点置于队列尾部。非公平锁时，如果持有锁的释放时，AQS会从队列中第一个线程唤醒。
AQS提供两种锁机制：排它锁（同一时刻只允许一个线程访问，如reentrantLock），共享锁（同一时刻允许多个线程同时获得锁资源，countDownLatch、semaphore）

53、**`什么是CAS`**
    compare and swap，是一项乐观锁技术。cas包含三个操作数，V（内存位置的值），A（预期原值），B（新值），先比较A和V取出值是否相等，相等替换B，否则不做任何操作。多个线程
  尝试使用cas修改一个变量时，只有一个线程能修改成功，其他的都会失败，但不会挂起，而是告知竞争失败，下次继续尝试。cas主要应用于乐观锁和自旋锁。
'ABA'问题：cas会导致ABA问题，两个线程都从内存中取出数据A，线程2操作了A数据变成B，然后又变为A写入到V内存位置中，线程1这时候发现内存V中值还是A，线程1就操作成功。虽然线程1cas
操作成功，但是整个过程有问题。如何解决：通过版本号（version）来解决，每次修改时带上这个版本号，一旦版本号对不上执行就失败，成功就version + 1。Java中有一个工具
AtomicStampedReference在多线程环境下解决ABA问题，它里面利用时间戳来解决。

54、**`synchronized和reentrantLock区别`**
    他们两都是线程同步控制，但是reentrantLock功能丰富得多。两者相同点都是可重入锁。不同点：01：synchronized时Java内置特性，而reentrantLock时Java代码实现的。
02：sync时可自动获取/释放锁，lock需要手动。03：lock具有响应中断、超时等待等特性。04：lock可以实现公平锁和非公平锁，sync是能非公平锁。
非公平锁就是多个线程不按照申请锁的顺序区获取锁，直接来了就获取锁，获不到就进入队列（优点时吞吐效率高点，减少唤起线程的开销）。
公平锁就是按照申请锁的顺序获取锁，先到先得（有点事所有线程都能得到资源，但是吞吐量下降很多）。

55、**`countDownLatch、cyclicBarrier、semaphore区别？`**
    01：countDownLatch是一个计数器，适用于一个线程等待多个线程完成操作的情况。02：cyclicBarrier适用于多个线程在桶一个屏障处等待。
    03：semaphore适用一个线程需要等待获取许可证才能访问。
    实践题：三个线程T1、T2、T3如何保证顺序执行：可以通过join，还可以通过countDownLatch、cyclicBarrier和semaphore实现通信，如果想让线程排队，可以通过线程池和
  completableFuture实现
  
56、**`forkJoinPool和thredPoolExecutor区别`**
    首先是实现方式上：forkJoinPool基于工作窃取算法实现的线程池，当一个线程执行完，从其他线程threadPoolExecutor基于任务分配实现的线程池，里面有一个共享的工作队列，
从队列获取任务执行。
    从使用场景上看：forkJoin适合01：大任务分解为小任务， 02：cpu密集型任务 03：异构任务并行处理 04：数据聚合任务
            executorService更适合处理较小的，相对独立的任务。比如网络请求、数据库处理等

57、**`有哪些保证线程安全的方案`**
    01：单线程（直接不支持多线程，比如redis）02：互斥锁（加锁嘛，synchronized、reentrantLock、分布式锁都是） 03：读写分离（COW写时分离技术，读共享，写加锁）
04：原子操作（AtomicInteger）05：不可变模式（如string中的不可变性，只有读属性，没有写属性）06：数据不共享（threadLocal）

58、**`如何实现主线程捕获子线程异常`**
    01：使用future 02：使用uncaughtExceptionHandler 03: completableFuture

59、**`什么是happens-before原则`**
    为什么volatile、synchronized可以保证可见性、有序性，正是他们遵守了happens-before原则。它是一个用于描述多线程程序中执行顺序的规则，属于JMM的一部分。如果一个操作A
    happen-before 另一个操作B，那么A的结果对B是可见的。 它里面总共有8个规则，我只说前面最重要的5个：01、程序顺序规则（一线程内按照代码顺序执行）
    02：解锁规则（解锁前的操作内容对下一个加锁是可见的）03：volatile变量规则（写操作happens-before读操作）04：传递规则（A H-B B，B H-B C, A happens-before C）
    05: 线程启动规则

60、**`AQS的独占模式和共享模式，为何采用双向链表`**
    独占模式是指一个线程只能一个线程获取同步状态，如互斥锁，reentrantLock。共享模式允许多个线程同时获取同步状态，如semaphore和readWriteLock。
    独占模式中状态通常表示是否被锁定，0表示未锁定，1表示锁定。共享模式，状态表示可使用的资源数量。
    AQS采用双向链表是为了01：高效的中断支持 （中断时需要将中断的线程节点从AQS同步队列中移除） 02：高效的挂起支持（执行挂起时，需要检查等待队列中的节点状态决定线程是否挂起）
     03：高效的线程判断
    

### 终于搞完并发，开始JVM了
    
    


**方法区是如何实现的？**
方法区是Java虚拟机规范定义的一块存储类信息、常量、静态变量、编译器编译后的代码等数据内存区域。jdk7之前，方法区被叫做永久代。1.6的时候包含字符串常量池，不过1.7之后放到堆内存中了。
1.8之后方法区又叫做元空间，是直接使用本地内存存储，不在位于堆中。字符串常量池是在编译时放入常量池中，是Java的一块特殊内存区域。字符串常量池数据有两个来源，字面量常量，intern方法
    

